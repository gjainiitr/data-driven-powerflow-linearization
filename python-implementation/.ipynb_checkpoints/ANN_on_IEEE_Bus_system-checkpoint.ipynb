{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fixed-circle",
   "metadata": {
    "id": "fixed-circle"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "#import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-cooler",
   "metadata": {
    "id": "pointed-cooler"
   },
   "outputs": [],
   "source": [
    "# Do this just once - No need to do any more\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XaYIkcdnAk4j",
   "metadata": {
    "id": "XaYIkcdnAk4j"
   },
   "outputs": [],
   "source": [
    "id = \"1EcWRAgZcqNwH9g9Ko-TkZvAZQSaTeZOu\" # 30P\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('30P.csv')  \n",
    "P = pd.read_csv('30P.csv', header=None)\n",
    "\n",
    "id = \"1pfx3L4ivHItHUlgvQKlmZZPVWS14rt81\" # 30Q\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('30Q.csv')  \n",
    "Q = pd.read_csv('30Q.csv', header=None)\n",
    "\n",
    "id = \"1Dq9lxJ5AI-IzX2lSmeENdV7iUvWam4Ev\" # 30V\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('30V.csv')  \n",
    "V = pd.read_csv('30V.csv', header=None)\n",
    "\n",
    "id = \"1P1h6FFRnFN0YyXP9S-4nJt5uYVV_KaIf\" # 30Va\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('30Va.csv')  \n",
    "Va = pd.read_csv('30Va.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XHoM3R_8AzDC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1614939823318,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "XHoM3R_8AzDC",
    "outputId": "b297c445-881d-4101-ef4d-0716f115d49d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 30)\n",
      "(500, 30)\n",
      "(500, 30)\n",
      "(500, 30)\n"
     ]
    }
   ],
   "source": [
    "print(P.shape)\n",
    "print(Q.shape)\n",
    "print(V.shape)\n",
    "print(Va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wBgl4XjKB1kc",
   "metadata": {
    "id": "wBgl4XjKB1kc"
   },
   "outputs": [],
   "source": [
    "num_train = P.shape[0]\n",
    "num_bus = P.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CGn-mL40FRyZ",
   "metadata": {
    "id": "CGn-mL40FRyZ"
   },
   "outputs": [],
   "source": [
    "pi = 3.141592\n",
    "X = P.join(Q, lsuffix='_P', rsuffix='_Q')\n",
    "Va = Va*pi/180\n",
    "Y = Va.join(V, lsuffix='_V', rsuffix='_Va')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HKeukJmnGh9V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "executionInfo": {
     "elapsed": 11325,
     "status": "ok",
     "timestamp": 1614926734151,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "HKeukJmnGh9V",
    "outputId": "df937e15-84c5-41da-b120-d9e5fc68a0dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.063566</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>-0.005809</td>\n",
       "      <td>-0.011914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032902</td>\n",
       "      <td>-0.064622</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015810</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026168</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>-0.016219</td>\n",
       "      <td>-0.007399</td>\n",
       "      <td>-0.021160</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>-0.021024</td>\n",
       "      <td>-0.003103</td>\n",
       "      <td>-0.030761</td>\n",
       "      <td>0.191103</td>\n",
       "      <td>0.016184</td>\n",
       "      <td>-0.023019</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007995</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004479</td>\n",
       "      <td>-0.017338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.050813</td>\n",
       "      <td>-0.022238</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>-0.010594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.041085</td>\n",
       "      <td>-0.046435</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014869</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.020894</td>\n",
       "      <td>0.048309</td>\n",
       "      <td>-0.013162</td>\n",
       "      <td>-0.015747</td>\n",
       "      <td>-0.007955</td>\n",
       "      <td>-0.021119</td>\n",
       "      <td>-0.006065</td>\n",
       "      <td>-0.018682</td>\n",
       "      <td>-0.005194</td>\n",
       "      <td>-0.038309</td>\n",
       "      <td>0.196720</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>-0.015355</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005342</td>\n",
       "      <td>-0.030119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.060845</td>\n",
       "      <td>-0.005310</td>\n",
       "      <td>-0.004678</td>\n",
       "      <td>-0.010883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.046335</td>\n",
       "      <td>-0.040606</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014204</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022053</td>\n",
       "      <td>0.052565</td>\n",
       "      <td>-0.010272</td>\n",
       "      <td>-0.020821</td>\n",
       "      <td>-0.006162</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>-0.005936</td>\n",
       "      <td>-0.021995</td>\n",
       "      <td>-0.003709</td>\n",
       "      <td>-0.047911</td>\n",
       "      <td>0.198475</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>-0.014389</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004487</td>\n",
       "      <td>0.040297</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005824</td>\n",
       "      <td>-0.023755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.041111</td>\n",
       "      <td>-0.011279</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>-0.011919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044798</td>\n",
       "      <td>-0.066736</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014178</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>-0.012375</td>\n",
       "      <td>-0.020417</td>\n",
       "      <td>-0.008902</td>\n",
       "      <td>-0.013725</td>\n",
       "      <td>-0.006833</td>\n",
       "      <td>-0.019464</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>-0.031267</td>\n",
       "      <td>0.186619</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>-0.019294</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006415</td>\n",
       "      <td>0.045975</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005982</td>\n",
       "      <td>-0.020183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.045556</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>-0.004930</td>\n",
       "      <td>-0.011484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053478</td>\n",
       "      <td>-0.068023</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.025648</td>\n",
       "      <td>0.054640</td>\n",
       "      <td>-0.014719</td>\n",
       "      <td>-0.014404</td>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.014072</td>\n",
       "      <td>-0.005283</td>\n",
       "      <td>-0.015872</td>\n",
       "      <td>-0.003360</td>\n",
       "      <td>-0.039034</td>\n",
       "      <td>0.182088</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>-0.017483</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007617</td>\n",
       "      <td>0.058169</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005796</td>\n",
       "      <td>-0.021576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.042523</td>\n",
       "      <td>-0.022551</td>\n",
       "      <td>-0.003933</td>\n",
       "      <td>-0.015178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.043032</td>\n",
       "      <td>-0.042178</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009702</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022193</td>\n",
       "      <td>0.052970</td>\n",
       "      <td>-0.013319</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-0.006084</td>\n",
       "      <td>-0.020206</td>\n",
       "      <td>-0.005047</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.003933</td>\n",
       "      <td>-0.026484</td>\n",
       "      <td>0.158677</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>-0.016359</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007668</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004253</td>\n",
       "      <td>-0.020347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-0.067206</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>-0.006615</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053654</td>\n",
       "      <td>-0.050461</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009850</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.018718</td>\n",
       "      <td>0.050082</td>\n",
       "      <td>-0.014733</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>-0.006925</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>-0.006079</td>\n",
       "      <td>-0.020269</td>\n",
       "      <td>-0.003620</td>\n",
       "      <td>-0.047755</td>\n",
       "      <td>0.201811</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>-0.018051</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005987</td>\n",
       "      <td>0.045617</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004930</td>\n",
       "      <td>-0.022992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-0.069711</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>-0.005221</td>\n",
       "      <td>-0.017407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044285</td>\n",
       "      <td>-0.048869</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012363</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026673</td>\n",
       "      <td>0.064050</td>\n",
       "      <td>-0.012235</td>\n",
       "      <td>-0.019958</td>\n",
       "      <td>-0.009606</td>\n",
       "      <td>-0.019849</td>\n",
       "      <td>-0.007646</td>\n",
       "      <td>-0.022253</td>\n",
       "      <td>-0.005770</td>\n",
       "      <td>-0.031090</td>\n",
       "      <td>0.183170</td>\n",
       "      <td>0.017106</td>\n",
       "      <td>-0.015223</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>0.050517</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005635</td>\n",
       "      <td>-0.023201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.031623</td>\n",
       "      <td>-0.023300</td>\n",
       "      <td>-0.005639</td>\n",
       "      <td>-0.020685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040114</td>\n",
       "      <td>-0.058862</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016712</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027531</td>\n",
       "      <td>0.056258</td>\n",
       "      <td>-0.012736</td>\n",
       "      <td>-0.016421</td>\n",
       "      <td>-0.009449</td>\n",
       "      <td>-0.012789</td>\n",
       "      <td>-0.007648</td>\n",
       "      <td>-0.016120</td>\n",
       "      <td>-0.004104</td>\n",
       "      <td>-0.049165</td>\n",
       "      <td>0.203857</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>-0.015426</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005971</td>\n",
       "      <td>0.042763</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003934</td>\n",
       "      <td>-0.022666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.060468</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>-0.003901</td>\n",
       "      <td>-0.016288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036670</td>\n",
       "      <td>-0.061790</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009267</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019099</td>\n",
       "      <td>0.051919</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>-0.018064</td>\n",
       "      <td>-0.006391</td>\n",
       "      <td>-0.017329</td>\n",
       "      <td>-0.005921</td>\n",
       "      <td>-0.025440</td>\n",
       "      <td>-0.004380</td>\n",
       "      <td>-0.040436</td>\n",
       "      <td>0.193427</td>\n",
       "      <td>0.013735</td>\n",
       "      <td>-0.020400</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006012</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004496</td>\n",
       "      <td>-0.019381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3   ...        26  27        28        29\n",
       "0   -0.063566  0.002831 -0.005809 -0.011914  ...  0.042724   0 -0.004479 -0.017338\n",
       "1   -0.050813 -0.022238 -0.003406 -0.010594  ...  0.059930   0 -0.005342 -0.030119\n",
       "2   -0.060845 -0.005310 -0.004678 -0.010883  ...  0.040297   0 -0.005824 -0.023755\n",
       "3   -0.041111 -0.011279 -0.005003 -0.011919  ...  0.045975   0 -0.005982 -0.020183\n",
       "4   -0.045556 -0.002334 -0.004930 -0.011484  ...  0.058169   0 -0.005796 -0.021576\n",
       "..        ...       ...       ...       ...  ...       ...  ..       ...       ...\n",
       "495 -0.042523 -0.022551 -0.003933 -0.015178  ...  0.044920   0 -0.004253 -0.020347\n",
       "496 -0.067206  0.010925 -0.006615 -0.011726  ...  0.045617   0 -0.004930 -0.022992\n",
       "497 -0.069711  0.012002 -0.005221 -0.017407  ...  0.050517   0 -0.005635 -0.023201\n",
       "498 -0.031623 -0.023300 -0.005639 -0.020685  ...  0.042763   0 -0.003934 -0.022666\n",
       "499 -0.060468  0.000928 -0.003901 -0.016288  ...  0.039434   0 -0.004496 -0.019381\n",
       "\n",
       "[500 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xn1Uq5-pGX_E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "executionInfo": {
     "elapsed": 11320,
     "status": "ok",
     "timestamp": 1614926734152,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "Xn1Uq5-pGX_E",
    "outputId": "bae52d17-ac06-4e0e-8875-3beaf210f623"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_P</th>\n",
       "      <th>1_P</th>\n",
       "      <th>2_P</th>\n",
       "      <th>3_P</th>\n",
       "      <th>4_P</th>\n",
       "      <th>5_P</th>\n",
       "      <th>6_P</th>\n",
       "      <th>7_P</th>\n",
       "      <th>8_P</th>\n",
       "      <th>9_P</th>\n",
       "      <th>10_P</th>\n",
       "      <th>11_P</th>\n",
       "      <th>12_P</th>\n",
       "      <th>13_P</th>\n",
       "      <th>14_P</th>\n",
       "      <th>15_P</th>\n",
       "      <th>16_P</th>\n",
       "      <th>17_P</th>\n",
       "      <th>18_P</th>\n",
       "      <th>19_P</th>\n",
       "      <th>20_P</th>\n",
       "      <th>21_P</th>\n",
       "      <th>22_P</th>\n",
       "      <th>23_P</th>\n",
       "      <th>24_P</th>\n",
       "      <th>25_P</th>\n",
       "      <th>26_P</th>\n",
       "      <th>27_P</th>\n",
       "      <th>28_P</th>\n",
       "      <th>29_P</th>\n",
       "      <th>0_Q</th>\n",
       "      <th>1_Q</th>\n",
       "      <th>2_Q</th>\n",
       "      <th>3_Q</th>\n",
       "      <th>4_Q</th>\n",
       "      <th>5_Q</th>\n",
       "      <th>6_Q</th>\n",
       "      <th>7_Q</th>\n",
       "      <th>8_Q</th>\n",
       "      <th>9_Q</th>\n",
       "      <th>10_Q</th>\n",
       "      <th>11_Q</th>\n",
       "      <th>12_Q</th>\n",
       "      <th>13_Q</th>\n",
       "      <th>14_Q</th>\n",
       "      <th>15_Q</th>\n",
       "      <th>16_Q</th>\n",
       "      <th>17_Q</th>\n",
       "      <th>18_Q</th>\n",
       "      <th>19_Q</th>\n",
       "      <th>20_Q</th>\n",
       "      <th>21_Q</th>\n",
       "      <th>22_Q</th>\n",
       "      <th>23_Q</th>\n",
       "      <th>24_Q</th>\n",
       "      <th>25_Q</th>\n",
       "      <th>26_Q</th>\n",
       "      <th>27_Q</th>\n",
       "      <th>28_Q</th>\n",
       "      <th>29_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289138</td>\n",
       "      <td>0.386810</td>\n",
       "      <td>-0.025259</td>\n",
       "      <td>-0.065064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.217020</td>\n",
       "      <td>-0.335610</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.069215</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.119490</td>\n",
       "      <td>0.370674</td>\n",
       "      <td>-0.065594</td>\n",
       "      <td>-0.090881</td>\n",
       "      <td>-0.032939</td>\n",
       "      <td>-0.096448</td>\n",
       "      <td>-0.030730</td>\n",
       "      <td>-0.109549</td>\n",
       "      <td>-0.018795</td>\n",
       "      <td>-0.150767</td>\n",
       "      <td>0.217986</td>\n",
       "      <td>0.169203</td>\n",
       "      <td>-0.103894</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.035753</td>\n",
       "      <td>0.270650</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022493</td>\n",
       "      <td>-0.094140</td>\n",
       "      <td>-0.063566</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>-0.005809</td>\n",
       "      <td>-0.011914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032902</td>\n",
       "      <td>-0.064622</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015810</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026168</td>\n",
       "      <td>0.058109</td>\n",
       "      <td>-0.013762</td>\n",
       "      <td>-0.016219</td>\n",
       "      <td>-0.007399</td>\n",
       "      <td>-0.021160</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>-0.021024</td>\n",
       "      <td>-0.003103</td>\n",
       "      <td>-0.030761</td>\n",
       "      <td>0.191103</td>\n",
       "      <td>0.016184</td>\n",
       "      <td>-0.023019</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007995</td>\n",
       "      <td>0.042724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004479</td>\n",
       "      <td>-0.017338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.221698</td>\n",
       "      <td>0.392824</td>\n",
       "      <td>-0.022609</td>\n",
       "      <td>-0.068708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.211499</td>\n",
       "      <td>-0.253658</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.067194</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.102879</td>\n",
       "      <td>0.377353</td>\n",
       "      <td>-0.056723</td>\n",
       "      <td>-0.088094</td>\n",
       "      <td>-0.033602</td>\n",
       "      <td>-0.089478</td>\n",
       "      <td>-0.029576</td>\n",
       "      <td>-0.095452</td>\n",
       "      <td>-0.022101</td>\n",
       "      <td>-0.207326</td>\n",
       "      <td>0.221406</td>\n",
       "      <td>0.168764</td>\n",
       "      <td>-0.093917</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039794</td>\n",
       "      <td>0.271314</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027790</td>\n",
       "      <td>-0.122540</td>\n",
       "      <td>-0.050813</td>\n",
       "      <td>-0.022238</td>\n",
       "      <td>-0.003406</td>\n",
       "      <td>-0.010594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.041085</td>\n",
       "      <td>-0.046435</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014869</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.020894</td>\n",
       "      <td>0.048309</td>\n",
       "      <td>-0.013162</td>\n",
       "      <td>-0.015747</td>\n",
       "      <td>-0.007955</td>\n",
       "      <td>-0.021119</td>\n",
       "      <td>-0.006065</td>\n",
       "      <td>-0.018682</td>\n",
       "      <td>-0.005194</td>\n",
       "      <td>-0.038309</td>\n",
       "      <td>0.196720</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>-0.015355</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005342</td>\n",
       "      <td>-0.030119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256259</td>\n",
       "      <td>0.362425</td>\n",
       "      <td>-0.028771</td>\n",
       "      <td>-0.063439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.272328</td>\n",
       "      <td>-0.259059</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.066484</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.116416</td>\n",
       "      <td>0.374515</td>\n",
       "      <td>-0.057584</td>\n",
       "      <td>-0.094059</td>\n",
       "      <td>-0.036371</td>\n",
       "      <td>-0.073250</td>\n",
       "      <td>-0.033969</td>\n",
       "      <td>-0.090296</td>\n",
       "      <td>-0.017965</td>\n",
       "      <td>-0.201338</td>\n",
       "      <td>0.219831</td>\n",
       "      <td>0.162133</td>\n",
       "      <td>-0.072730</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028685</td>\n",
       "      <td>0.278228</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.024040</td>\n",
       "      <td>-0.097586</td>\n",
       "      <td>-0.060845</td>\n",
       "      <td>-0.005310</td>\n",
       "      <td>-0.004678</td>\n",
       "      <td>-0.010883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.046335</td>\n",
       "      <td>-0.040606</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014204</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022053</td>\n",
       "      <td>0.052565</td>\n",
       "      <td>-0.010272</td>\n",
       "      <td>-0.020821</td>\n",
       "      <td>-0.006162</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>-0.005936</td>\n",
       "      <td>-0.021995</td>\n",
       "      <td>-0.003709</td>\n",
       "      <td>-0.047911</td>\n",
       "      <td>0.198475</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>-0.014389</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004487</td>\n",
       "      <td>0.040297</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005824</td>\n",
       "      <td>-0.023755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.201461</td>\n",
       "      <td>0.413184</td>\n",
       "      <td>-0.021352</td>\n",
       "      <td>-0.073854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247898</td>\n",
       "      <td>-0.282699</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.064982</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.096403</td>\n",
       "      <td>0.370918</td>\n",
       "      <td>-0.053454</td>\n",
       "      <td>-0.084641</td>\n",
       "      <td>-0.040761</td>\n",
       "      <td>-0.076120</td>\n",
       "      <td>-0.030615</td>\n",
       "      <td>-0.109583</td>\n",
       "      <td>-0.020349</td>\n",
       "      <td>-0.174204</td>\n",
       "      <td>0.218049</td>\n",
       "      <td>0.167219</td>\n",
       "      <td>-0.085982</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.038623</td>\n",
       "      <td>0.269910</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.024597</td>\n",
       "      <td>-0.095403</td>\n",
       "      <td>-0.041111</td>\n",
       "      <td>-0.011279</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>-0.011919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044798</td>\n",
       "      <td>-0.066736</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014178</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.050795</td>\n",
       "      <td>-0.012375</td>\n",
       "      <td>-0.020417</td>\n",
       "      <td>-0.008902</td>\n",
       "      <td>-0.013725</td>\n",
       "      <td>-0.006833</td>\n",
       "      <td>-0.019464</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>-0.031267</td>\n",
       "      <td>0.186619</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>-0.019294</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006415</td>\n",
       "      <td>0.045975</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005982</td>\n",
       "      <td>-0.020183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.224660</td>\n",
       "      <td>0.412070</td>\n",
       "      <td>-0.025464</td>\n",
       "      <td>-0.068621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.220082</td>\n",
       "      <td>-0.341731</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059276</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.109150</td>\n",
       "      <td>0.373017</td>\n",
       "      <td>-0.059214</td>\n",
       "      <td>-0.086136</td>\n",
       "      <td>-0.029862</td>\n",
       "      <td>-0.074759</td>\n",
       "      <td>-0.027128</td>\n",
       "      <td>-0.085339</td>\n",
       "      <td>-0.020432</td>\n",
       "      <td>-0.168495</td>\n",
       "      <td>0.221381</td>\n",
       "      <td>0.166463</td>\n",
       "      <td>-0.091711</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.037464</td>\n",
       "      <td>0.276907</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026778</td>\n",
       "      <td>-0.122817</td>\n",
       "      <td>-0.045556</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>-0.004930</td>\n",
       "      <td>-0.011484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053478</td>\n",
       "      <td>-0.068023</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.025648</td>\n",
       "      <td>0.054640</td>\n",
       "      <td>-0.014719</td>\n",
       "      <td>-0.014404</td>\n",
       "      <td>-0.007316</td>\n",
       "      <td>-0.014072</td>\n",
       "      <td>-0.005283</td>\n",
       "      <td>-0.015872</td>\n",
       "      <td>-0.003360</td>\n",
       "      <td>-0.039034</td>\n",
       "      <td>0.182088</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>-0.017483</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007617</td>\n",
       "      <td>0.058169</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005796</td>\n",
       "      <td>-0.021576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.187495</td>\n",
       "      <td>0.383552</td>\n",
       "      <td>-0.023053</td>\n",
       "      <td>-0.061565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253489</td>\n",
       "      <td>-0.264949</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053921</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.104629</td>\n",
       "      <td>0.375855</td>\n",
       "      <td>-0.072780</td>\n",
       "      <td>-0.092613</td>\n",
       "      <td>-0.038344</td>\n",
       "      <td>-0.082296</td>\n",
       "      <td>-0.029925</td>\n",
       "      <td>-0.091039</td>\n",
       "      <td>-0.018105</td>\n",
       "      <td>-0.140529</td>\n",
       "      <td>0.222398</td>\n",
       "      <td>0.165966</td>\n",
       "      <td>-0.095630</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032510</td>\n",
       "      <td>0.269888</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.021254</td>\n",
       "      <td>-0.110917</td>\n",
       "      <td>-0.042523</td>\n",
       "      <td>-0.022551</td>\n",
       "      <td>-0.003933</td>\n",
       "      <td>-0.015178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.043032</td>\n",
       "      <td>-0.042178</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009702</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022193</td>\n",
       "      <td>0.052970</td>\n",
       "      <td>-0.013319</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-0.006084</td>\n",
       "      <td>-0.020206</td>\n",
       "      <td>-0.005047</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.003933</td>\n",
       "      <td>-0.026484</td>\n",
       "      <td>0.158677</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>-0.016359</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007668</td>\n",
       "      <td>0.044920</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004253</td>\n",
       "      <td>-0.020347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.354855</td>\n",
       "      <td>-0.027200</td>\n",
       "      <td>-0.073399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.269482</td>\n",
       "      <td>-0.244752</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.117357</td>\n",
       "      <td>0.376179</td>\n",
       "      <td>-0.061499</td>\n",
       "      <td>-0.079611</td>\n",
       "      <td>-0.029445</td>\n",
       "      <td>-0.093565</td>\n",
       "      <td>-0.029902</td>\n",
       "      <td>-0.091058</td>\n",
       "      <td>-0.024031</td>\n",
       "      <td>-0.209228</td>\n",
       "      <td>0.222430</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>-0.083229</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.033269</td>\n",
       "      <td>0.276798</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.024254</td>\n",
       "      <td>-0.108711</td>\n",
       "      <td>-0.067206</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>-0.006615</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053654</td>\n",
       "      <td>-0.050461</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009850</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.018718</td>\n",
       "      <td>0.050082</td>\n",
       "      <td>-0.014733</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>-0.006925</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>-0.006079</td>\n",
       "      <td>-0.020269</td>\n",
       "      <td>-0.003620</td>\n",
       "      <td>-0.047755</td>\n",
       "      <td>0.201811</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>-0.018051</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005987</td>\n",
       "      <td>0.045617</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004930</td>\n",
       "      <td>-0.022992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.320943</td>\n",
       "      <td>0.403464</td>\n",
       "      <td>-0.023075</td>\n",
       "      <td>-0.083035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.266268</td>\n",
       "      <td>-0.296323</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053274</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.134081</td>\n",
       "      <td>0.374449</td>\n",
       "      <td>-0.071487</td>\n",
       "      <td>-0.095787</td>\n",
       "      <td>-0.041600</td>\n",
       "      <td>-0.102680</td>\n",
       "      <td>-0.038207</td>\n",
       "      <td>-0.102301</td>\n",
       "      <td>-0.025528</td>\n",
       "      <td>-0.154115</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>0.166264</td>\n",
       "      <td>-0.089047</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.029932</td>\n",
       "      <td>0.277876</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.025600</td>\n",
       "      <td>-0.113135</td>\n",
       "      <td>-0.069711</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>-0.005221</td>\n",
       "      <td>-0.017407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.044285</td>\n",
       "      <td>-0.048869</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012363</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026673</td>\n",
       "      <td>0.064050</td>\n",
       "      <td>-0.012235</td>\n",
       "      <td>-0.019958</td>\n",
       "      <td>-0.009606</td>\n",
       "      <td>-0.019849</td>\n",
       "      <td>-0.007646</td>\n",
       "      <td>-0.022253</td>\n",
       "      <td>-0.005770</td>\n",
       "      <td>-0.031090</td>\n",
       "      <td>0.183170</td>\n",
       "      <td>0.017106</td>\n",
       "      <td>-0.015223</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>0.050517</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005635</td>\n",
       "      <td>-0.023201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.177657</td>\n",
       "      <td>0.438713</td>\n",
       "      <td>-0.022946</td>\n",
       "      <td>-0.084554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.217495</td>\n",
       "      <td>-0.258012</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.067975</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.118631</td>\n",
       "      <td>0.379003</td>\n",
       "      <td>-0.068927</td>\n",
       "      <td>-0.082919</td>\n",
       "      <td>-0.038342</td>\n",
       "      <td>-0.080812</td>\n",
       "      <td>-0.035221</td>\n",
       "      <td>-0.085032</td>\n",
       "      <td>-0.021684</td>\n",
       "      <td>-0.197634</td>\n",
       "      <td>0.220090</td>\n",
       "      <td>0.165993</td>\n",
       "      <td>-0.095082</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.037150</td>\n",
       "      <td>0.272258</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023606</td>\n",
       "      <td>-0.099023</td>\n",
       "      <td>-0.031623</td>\n",
       "      <td>-0.023300</td>\n",
       "      <td>-0.005639</td>\n",
       "      <td>-0.020685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040114</td>\n",
       "      <td>-0.058862</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016712</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027531</td>\n",
       "      <td>0.056258</td>\n",
       "      <td>-0.012736</td>\n",
       "      <td>-0.016421</td>\n",
       "      <td>-0.009449</td>\n",
       "      <td>-0.012789</td>\n",
       "      <td>-0.007648</td>\n",
       "      <td>-0.016120</td>\n",
       "      <td>-0.004104</td>\n",
       "      <td>-0.049165</td>\n",
       "      <td>0.203857</td>\n",
       "      <td>0.009162</td>\n",
       "      <td>-0.015426</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005971</td>\n",
       "      <td>0.042763</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003934</td>\n",
       "      <td>-0.022666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.270201</td>\n",
       "      <td>0.370491</td>\n",
       "      <td>-0.022660</td>\n",
       "      <td>-0.071965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.197233</td>\n",
       "      <td>-0.358957</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.052941</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.113782</td>\n",
       "      <td>0.374111</td>\n",
       "      <td>-0.050053</td>\n",
       "      <td>-0.094163</td>\n",
       "      <td>-0.028194</td>\n",
       "      <td>-0.098178</td>\n",
       "      <td>-0.033876</td>\n",
       "      <td>-0.112058</td>\n",
       "      <td>-0.021730</td>\n",
       "      <td>-0.165267</td>\n",
       "      <td>0.220957</td>\n",
       "      <td>0.161154</td>\n",
       "      <td>-0.090884</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028357</td>\n",
       "      <td>0.270709</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.021268</td>\n",
       "      <td>-0.086402</td>\n",
       "      <td>-0.060468</td>\n",
       "      <td>0.000928</td>\n",
       "      <td>-0.003901</td>\n",
       "      <td>-0.016288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036670</td>\n",
       "      <td>-0.061790</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009267</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019099</td>\n",
       "      <td>0.051919</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>-0.018064</td>\n",
       "      <td>-0.006391</td>\n",
       "      <td>-0.017329</td>\n",
       "      <td>-0.005921</td>\n",
       "      <td>-0.025440</td>\n",
       "      <td>-0.004380</td>\n",
       "      <td>-0.040436</td>\n",
       "      <td>0.193427</td>\n",
       "      <td>0.013735</td>\n",
       "      <td>-0.020400</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006012</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004496</td>\n",
       "      <td>-0.019381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_P       1_P       2_P       3_P  ...      26_Q  27_Q      28_Q      29_Q\n",
       "0    0.289138  0.386810 -0.025259 -0.065064  ...  0.042724     0 -0.004479 -0.017338\n",
       "1    0.221698  0.392824 -0.022609 -0.068708  ...  0.059930     0 -0.005342 -0.030119\n",
       "2    0.256259  0.362425 -0.028771 -0.063439  ...  0.040297     0 -0.005824 -0.023755\n",
       "3    0.201461  0.413184 -0.021352 -0.073854  ...  0.045975     0 -0.005982 -0.020183\n",
       "4    0.224660  0.412070 -0.025464 -0.068621  ...  0.058169     0 -0.005796 -0.021576\n",
       "..        ...       ...       ...       ...  ...       ...   ...       ...       ...\n",
       "495  0.187495  0.383552 -0.023053 -0.061565  ...  0.044920     0 -0.004253 -0.020347\n",
       "496  0.289773  0.354855 -0.027200 -0.073399  ...  0.045617     0 -0.004930 -0.022992\n",
       "497  0.320943  0.403464 -0.023075 -0.083035  ...  0.050517     0 -0.005635 -0.023201\n",
       "498  0.177657  0.438713 -0.022946 -0.084554  ...  0.042763     0 -0.003934 -0.022666\n",
       "499  0.270201  0.370491 -0.022660 -0.071965  ...  0.039434     0 -0.004496 -0.019381\n",
       "\n",
       "[500 rows x 60 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BrQzlMdYO2-e",
   "metadata": {
    "id": "BrQzlMdYO2-e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wCDinmt16pr9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "executionInfo": {
     "elapsed": 1706,
     "status": "ok",
     "timestamp": 1614939880187,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "wCDinmt16pr9",
    "outputId": "5ede7e6a-2aae-42d6-d71d-da8c19153c83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_P</th>\n",
       "      <th>1_P</th>\n",
       "      <th>2_P</th>\n",
       "      <th>3_P</th>\n",
       "      <th>4_P</th>\n",
       "      <th>5_P</th>\n",
       "      <th>6_P</th>\n",
       "      <th>7_P</th>\n",
       "      <th>8_P</th>\n",
       "      <th>9_P</th>\n",
       "      <th>10_P</th>\n",
       "      <th>11_P</th>\n",
       "      <th>12_P</th>\n",
       "      <th>13_P</th>\n",
       "      <th>14_P</th>\n",
       "      <th>15_P</th>\n",
       "      <th>16_P</th>\n",
       "      <th>17_P</th>\n",
       "      <th>18_P</th>\n",
       "      <th>19_P</th>\n",
       "      <th>20_P</th>\n",
       "      <th>21_P</th>\n",
       "      <th>22_P</th>\n",
       "      <th>23_P</th>\n",
       "      <th>24_P</th>\n",
       "      <th>25_P</th>\n",
       "      <th>26_P</th>\n",
       "      <th>27_P</th>\n",
       "      <th>28_P</th>\n",
       "      <th>29_P</th>\n",
       "      <th>0_Q</th>\n",
       "      <th>1_Q</th>\n",
       "      <th>2_Q</th>\n",
       "      <th>3_Q</th>\n",
       "      <th>4_Q</th>\n",
       "      <th>5_Q</th>\n",
       "      <th>6_Q</th>\n",
       "      <th>7_Q</th>\n",
       "      <th>8_Q</th>\n",
       "      <th>9_Q</th>\n",
       "      <th>10_Q</th>\n",
       "      <th>11_Q</th>\n",
       "      <th>12_Q</th>\n",
       "      <th>13_Q</th>\n",
       "      <th>14_Q</th>\n",
       "      <th>15_Q</th>\n",
       "      <th>16_Q</th>\n",
       "      <th>17_Q</th>\n",
       "      <th>18_Q</th>\n",
       "      <th>19_Q</th>\n",
       "      <th>20_Q</th>\n",
       "      <th>21_Q</th>\n",
       "      <th>22_Q</th>\n",
       "      <th>23_Q</th>\n",
       "      <th>24_Q</th>\n",
       "      <th>25_Q</th>\n",
       "      <th>26_Q</th>\n",
       "      <th>27_Q</th>\n",
       "      <th>28_Q</th>\n",
       "      <th>29_Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.197855</td>\n",
       "      <td>0.417068</td>\n",
       "      <td>-0.026884</td>\n",
       "      <td>-0.075950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.246492</td>\n",
       "      <td>-0.301999</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.057990</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.091396</td>\n",
       "      <td>0.379089</td>\n",
       "      <td>-0.053602</td>\n",
       "      <td>-0.098247</td>\n",
       "      <td>-0.029305</td>\n",
       "      <td>-0.086087</td>\n",
       "      <td>-0.036232</td>\n",
       "      <td>-0.092839</td>\n",
       "      <td>-0.022305</td>\n",
       "      <td>-0.152862</td>\n",
       "      <td>0.218820</td>\n",
       "      <td>0.164536</td>\n",
       "      <td>-0.082371</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039180</td>\n",
       "      <td>0.277285</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022351</td>\n",
       "      <td>-0.118883</td>\n",
       "      <td>-0.039736</td>\n",
       "      <td>-0.014518</td>\n",
       "      <td>-0.005801</td>\n",
       "      <td>-0.014347</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040891</td>\n",
       "      <td>-0.066229</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.013607</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014522</td>\n",
       "      <td>0.049367</td>\n",
       "      <td>-0.011103</td>\n",
       "      <td>-0.020863</td>\n",
       "      <td>-0.006439</td>\n",
       "      <td>-0.016492</td>\n",
       "      <td>-0.005937</td>\n",
       "      <td>-0.016805</td>\n",
       "      <td>-0.004935</td>\n",
       "      <td>-0.026177</td>\n",
       "      <td>0.168928</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>-0.012529</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008362</td>\n",
       "      <td>0.052223</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>-0.021125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.209560</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>-0.023610</td>\n",
       "      <td>-0.070654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.269775</td>\n",
       "      <td>-0.293745</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.051959</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.125652</td>\n",
       "      <td>0.372646</td>\n",
       "      <td>-0.058215</td>\n",
       "      <td>-0.090471</td>\n",
       "      <td>-0.036236</td>\n",
       "      <td>-0.075904</td>\n",
       "      <td>-0.028356</td>\n",
       "      <td>-0.080097</td>\n",
       "      <td>-0.025319</td>\n",
       "      <td>-0.162677</td>\n",
       "      <td>0.220425</td>\n",
       "      <td>0.169513</td>\n",
       "      <td>-0.081766</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.031993</td>\n",
       "      <td>0.277142</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027978</td>\n",
       "      <td>-0.106757</td>\n",
       "      <td>-0.041420</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>-0.004940</td>\n",
       "      <td>-0.011257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.053970</td>\n",
       "      <td>-0.070886</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009318</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028729</td>\n",
       "      <td>0.059693</td>\n",
       "      <td>-0.009965</td>\n",
       "      <td>-0.016793</td>\n",
       "      <td>-0.007944</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>-0.005480</td>\n",
       "      <td>-0.016899</td>\n",
       "      <td>-0.005539</td>\n",
       "      <td>-0.037332</td>\n",
       "      <td>0.183323</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>-0.018147</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006298</td>\n",
       "      <td>0.047873</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004661</td>\n",
       "      <td>-0.018896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.089164</td>\n",
       "      <td>0.438124</td>\n",
       "      <td>-0.028076</td>\n",
       "      <td>-0.068950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.188582</td>\n",
       "      <td>-0.271014</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063536</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.114942</td>\n",
       "      <td>0.374514</td>\n",
       "      <td>-0.066486</td>\n",
       "      <td>-0.068022</td>\n",
       "      <td>-0.035422</td>\n",
       "      <td>-0.106759</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>-0.087439</td>\n",
       "      <td>-0.024128</td>\n",
       "      <td>-0.158478</td>\n",
       "      <td>0.224792</td>\n",
       "      <td>0.164033</td>\n",
       "      <td>-0.095142</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.029989</td>\n",
       "      <td>0.276204</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.021695</td>\n",
       "      <td>-0.091641</td>\n",
       "      <td>-0.010302</td>\n",
       "      <td>-0.047151</td>\n",
       "      <td>-0.006749</td>\n",
       "      <td>-0.013933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.029495</td>\n",
       "      <td>-0.063814</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.015433</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027605</td>\n",
       "      <td>0.054520</td>\n",
       "      <td>-0.013096</td>\n",
       "      <td>-0.011345</td>\n",
       "      <td>-0.005607</td>\n",
       "      <td>-0.022773</td>\n",
       "      <td>-0.005513</td>\n",
       "      <td>-0.017194</td>\n",
       "      <td>-0.004129</td>\n",
       "      <td>-0.023795</td>\n",
       "      <td>0.171481</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>-0.014415</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005154</td>\n",
       "      <td>0.029911</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003831</td>\n",
       "      <td>-0.014957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.091554</td>\n",
       "      <td>0.422978</td>\n",
       "      <td>-0.027837</td>\n",
       "      <td>-0.072275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.212225</td>\n",
       "      <td>-0.259323</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.050788</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.101145</td>\n",
       "      <td>0.372193</td>\n",
       "      <td>-0.059002</td>\n",
       "      <td>-0.092178</td>\n",
       "      <td>-0.032045</td>\n",
       "      <td>-0.074385</td>\n",
       "      <td>-0.027712</td>\n",
       "      <td>-0.091649</td>\n",
       "      <td>-0.023753</td>\n",
       "      <td>-0.183804</td>\n",
       "      <td>0.220009</td>\n",
       "      <td>0.167453</td>\n",
       "      <td>-0.075233</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.035359</td>\n",
       "      <td>0.276893</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.021248</td>\n",
       "      <td>-0.095278</td>\n",
       "      <td>-0.014700</td>\n",
       "      <td>-0.049394</td>\n",
       "      <td>-0.006741</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.043930</td>\n",
       "      <td>-0.042479</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009549</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.018720</td>\n",
       "      <td>0.047775</td>\n",
       "      <td>-0.011621</td>\n",
       "      <td>-0.016264</td>\n",
       "      <td>-0.005622</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>-0.005709</td>\n",
       "      <td>-0.015523</td>\n",
       "      <td>-0.003797</td>\n",
       "      <td>-0.033090</td>\n",
       "      <td>0.167102</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006831</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.003241</td>\n",
       "      <td>-0.015565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.230783</td>\n",
       "      <td>0.370517</td>\n",
       "      <td>-0.021920</td>\n",
       "      <td>-0.061084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.206853</td>\n",
       "      <td>-0.327502</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.052389</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108935</td>\n",
       "      <td>0.373321</td>\n",
       "      <td>-0.059892</td>\n",
       "      <td>-0.091901</td>\n",
       "      <td>-0.031918</td>\n",
       "      <td>-0.098726</td>\n",
       "      <td>-0.037058</td>\n",
       "      <td>-0.104076</td>\n",
       "      <td>-0.025912</td>\n",
       "      <td>-0.158068</td>\n",
       "      <td>0.224959</td>\n",
       "      <td>0.167317</td>\n",
       "      <td>-0.080314</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036380</td>\n",
       "      <td>0.278635</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028722</td>\n",
       "      <td>-0.094827</td>\n",
       "      <td>-0.048883</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>-0.014077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.045061</td>\n",
       "      <td>-0.075933</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007859</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019167</td>\n",
       "      <td>0.053814</td>\n",
       "      <td>-0.011385</td>\n",
       "      <td>-0.015163</td>\n",
       "      <td>-0.005761</td>\n",
       "      <td>-0.016445</td>\n",
       "      <td>-0.006945</td>\n",
       "      <td>-0.022524</td>\n",
       "      <td>-0.005783</td>\n",
       "      <td>-0.025844</td>\n",
       "      <td>0.173722</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>-0.017700</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005980</td>\n",
       "      <td>0.042480</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006474</td>\n",
       "      <td>-0.015990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.191555</td>\n",
       "      <td>0.368754</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.069294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.226405</td>\n",
       "      <td>-0.244411</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.060875</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.107997</td>\n",
       "      <td>0.372808</td>\n",
       "      <td>-0.066402</td>\n",
       "      <td>-0.094902</td>\n",
       "      <td>-0.038834</td>\n",
       "      <td>-0.072700</td>\n",
       "      <td>-0.032238</td>\n",
       "      <td>-0.080197</td>\n",
       "      <td>-0.019517</td>\n",
       "      <td>-0.203205</td>\n",
       "      <td>0.223843</td>\n",
       "      <td>0.163319</td>\n",
       "      <td>-0.087624</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.030843</td>\n",
       "      <td>0.274452</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026353</td>\n",
       "      <td>-0.096317</td>\n",
       "      <td>-0.045274</td>\n",
       "      <td>-0.023820</td>\n",
       "      <td>-0.003237</td>\n",
       "      <td>-0.012569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047456</td>\n",
       "      <td>-0.037990</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012628</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.022433</td>\n",
       "      <td>0.049371</td>\n",
       "      <td>-0.010863</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>-0.007432</td>\n",
       "      <td>-0.012889</td>\n",
       "      <td>-0.007059</td>\n",
       "      <td>-0.019934</td>\n",
       "      <td>-0.003410</td>\n",
       "      <td>-0.046053</td>\n",
       "      <td>0.190835</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>-0.021034</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>0.040296</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006482</td>\n",
       "      <td>-0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.147556</td>\n",
       "      <td>0.372050</td>\n",
       "      <td>-0.019407</td>\n",
       "      <td>-0.089223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.208524</td>\n",
       "      <td>-0.274980</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.059677</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.101453</td>\n",
       "      <td>0.371777</td>\n",
       "      <td>-0.062350</td>\n",
       "      <td>-0.069624</td>\n",
       "      <td>-0.035472</td>\n",
       "      <td>-0.095817</td>\n",
       "      <td>-0.027753</td>\n",
       "      <td>-0.106730</td>\n",
       "      <td>-0.017682</td>\n",
       "      <td>-0.140657</td>\n",
       "      <td>0.217352</td>\n",
       "      <td>0.161819</td>\n",
       "      <td>-0.072979</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.029511</td>\n",
       "      <td>0.272355</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.025421</td>\n",
       "      <td>-0.089619</td>\n",
       "      <td>-0.029147</td>\n",
       "      <td>-0.019258</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>-0.018738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.061484</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.013186</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023274</td>\n",
       "      <td>0.055747</td>\n",
       "      <td>-0.015225</td>\n",
       "      <td>-0.015014</td>\n",
       "      <td>-0.006184</td>\n",
       "      <td>-0.017050</td>\n",
       "      <td>-0.004425</td>\n",
       "      <td>-0.023271</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>-0.029156</td>\n",
       "      <td>0.173881</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>-0.018041</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006790</td>\n",
       "      <td>0.039066</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>-0.018860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.154173</td>\n",
       "      <td>0.405426</td>\n",
       "      <td>-0.023410</td>\n",
       "      <td>-0.063569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.201227</td>\n",
       "      <td>-0.332200</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.055939</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.116247</td>\n",
       "      <td>0.376247</td>\n",
       "      <td>-0.063444</td>\n",
       "      <td>-0.072729</td>\n",
       "      <td>-0.032713</td>\n",
       "      <td>-0.084968</td>\n",
       "      <td>-0.031043</td>\n",
       "      <td>-0.107919</td>\n",
       "      <td>-0.020931</td>\n",
       "      <td>-0.141709</td>\n",
       "      <td>0.219005</td>\n",
       "      <td>0.161585</td>\n",
       "      <td>-0.070456</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034858</td>\n",
       "      <td>0.273365</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.026762</td>\n",
       "      <td>-0.092465</td>\n",
       "      <td>-0.029275</td>\n",
       "      <td>-0.020504</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.048533</td>\n",
       "      <td>-0.061598</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012045</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028885</td>\n",
       "      <td>0.057840</td>\n",
       "      <td>-0.010759</td>\n",
       "      <td>-0.014315</td>\n",
       "      <td>-0.006729</td>\n",
       "      <td>-0.014904</td>\n",
       "      <td>-0.007745</td>\n",
       "      <td>-0.021008</td>\n",
       "      <td>-0.003255</td>\n",
       "      <td>-0.031125</td>\n",
       "      <td>0.170189</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>-0.012372</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007207</td>\n",
       "      <td>0.043899</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005727</td>\n",
       "      <td>-0.019426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.334376</td>\n",
       "      <td>0.355704</td>\n",
       "      <td>-0.021395</td>\n",
       "      <td>-0.073154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.210221</td>\n",
       "      <td>-0.353320</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.052191</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>0.378441</td>\n",
       "      <td>-0.067167</td>\n",
       "      <td>-0.074614</td>\n",
       "      <td>-0.035305</td>\n",
       "      <td>-0.104791</td>\n",
       "      <td>-0.036642</td>\n",
       "      <td>-0.105451</td>\n",
       "      <td>-0.021423</td>\n",
       "      <td>-0.187177</td>\n",
       "      <td>0.219132</td>\n",
       "      <td>0.161785</td>\n",
       "      <td>-0.081467</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032101</td>\n",
       "      <td>0.278739</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.023285</td>\n",
       "      <td>-0.101852</td>\n",
       "      <td>-0.073509</td>\n",
       "      <td>0.030970</td>\n",
       "      <td>-0.004063</td>\n",
       "      <td>-0.014777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040461</td>\n",
       "      <td>-0.083299</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.009105</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.030770</td>\n",
       "      <td>0.061221</td>\n",
       "      <td>-0.014093</td>\n",
       "      <td>-0.014723</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>-0.020679</td>\n",
       "      <td>-0.008005</td>\n",
       "      <td>-0.020234</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>-0.031899</td>\n",
       "      <td>0.195074</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>-0.013188</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.007907</td>\n",
       "      <td>0.049999</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005218</td>\n",
       "      <td>-0.023008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.201255</td>\n",
       "      <td>0.363877</td>\n",
       "      <td>-0.019294</td>\n",
       "      <td>-0.081910</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.205329</td>\n",
       "      <td>-0.324257</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.048565</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.106838</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>-0.061860</td>\n",
       "      <td>-0.090278</td>\n",
       "      <td>-0.039433</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.033358</td>\n",
       "      <td>-0.079595</td>\n",
       "      <td>-0.021370</td>\n",
       "      <td>-0.146975</td>\n",
       "      <td>0.217679</td>\n",
       "      <td>0.162548</td>\n",
       "      <td>-0.075440</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034365</td>\n",
       "      <td>0.272066</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.021767</td>\n",
       "      <td>-0.092616</td>\n",
       "      <td>-0.042149</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.003547</td>\n",
       "      <td>-0.016365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040361</td>\n",
       "      <td>-0.077586</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010589</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016519</td>\n",
       "      <td>0.053641</td>\n",
       "      <td>-0.011124</td>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.007759</td>\n",
       "      <td>-0.020807</td>\n",
       "      <td>-0.007606</td>\n",
       "      <td>-0.018527</td>\n",
       "      <td>-0.004120</td>\n",
       "      <td>-0.029458</td>\n",
       "      <td>0.172599</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>-0.014431</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>0.040581</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.004671</td>\n",
       "      <td>-0.017077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0_P       1_P       2_P       3_P  ...      26_Q  27_Q      28_Q      29_Q\n",
       "249  0.197855  0.417068 -0.026884 -0.075950  ...  0.052223     0 -0.004874 -0.021125\n",
       "433  0.209560  0.410599 -0.023610 -0.070654  ...  0.047873     0 -0.004661 -0.018896\n",
       "19   0.089164  0.438124 -0.028076 -0.068950  ...  0.029911     0 -0.003831 -0.014957\n",
       "322  0.091554  0.422978 -0.027837 -0.072275  ...  0.030578     0 -0.003241 -0.015565\n",
       "332  0.230783  0.370517 -0.021920 -0.061084  ...  0.042480     0 -0.006474 -0.015990\n",
       "..        ...       ...       ...       ...  ...       ...   ...       ...       ...\n",
       "106  0.191555  0.368754 -0.019610 -0.069294  ...  0.040296     0 -0.006482 -0.021500\n",
       "270  0.147556  0.372050 -0.019407 -0.089223  ...  0.039066     0 -0.004603 -0.018860\n",
       "348  0.154173  0.405426 -0.023410 -0.063569  ...  0.043899     0 -0.005727 -0.019426\n",
       "435  0.334376  0.355704 -0.021395 -0.073154  ...  0.049999     0 -0.005218 -0.023008\n",
       "102  0.201255  0.363877 -0.019294 -0.081910  ...  0.040581     0 -0.004671 -0.017077\n",
       "\n",
       "[400 rows x 60 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hC9bXn0Q6xyJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 999,
     "status": "ok",
     "timestamp": 1614940052980,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "hC9bXn0Q6xyJ",
    "outputId": "eb406094-20c4-4306-8d54-08f03061d508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0_P     0.191555\n",
       "1_P     0.368754\n",
       "2_P    -0.019610\n",
       "3_P    -0.069294\n",
       "4_P     0.000000\n",
       "5_P     0.000000\n",
       "6_P    -0.226405\n",
       "7_P    -0.244411\n",
       "8_P     0.000000\n",
       "9_P    -0.060875\n",
       "10_P    0.000000\n",
       "11_P   -0.107997\n",
       "12_P    0.372808\n",
       "13_P   -0.066402\n",
       "14_P   -0.094902\n",
       "15_P   -0.038834\n",
       "16_P   -0.072700\n",
       "17_P   -0.032238\n",
       "18_P   -0.080197\n",
       "19_P   -0.019517\n",
       "20_P   -0.203205\n",
       "21_P    0.223843\n",
       "22_P    0.163319\n",
       "23_P   -0.087624\n",
       "24_P    0.000000\n",
       "25_P   -0.030843\n",
       "26_P    0.274452\n",
       "27_P    0.000000\n",
       "28_P   -0.026353\n",
       "29_P   -0.096317\n",
       "0_Q    -0.045274\n",
       "1_Q    -0.023820\n",
       "2_Q    -0.003237\n",
       "3_Q    -0.012569\n",
       "4_Q     0.000000\n",
       "5_Q     0.000000\n",
       "6_Q    -0.047456\n",
       "7_Q    -0.037990\n",
       "8_Q     0.000000\n",
       "9_Q    -0.012628\n",
       "10_Q    0.000000\n",
       "11_Q   -0.022433\n",
       "12_Q    0.049371\n",
       "13_Q   -0.010863\n",
       "14_Q   -0.014567\n",
       "15_Q   -0.007432\n",
       "16_Q   -0.012889\n",
       "17_Q   -0.007059\n",
       "18_Q   -0.019934\n",
       "19_Q   -0.003410\n",
       "20_Q   -0.046053\n",
       "21_Q    0.190835\n",
       "22_Q    0.007702\n",
       "23_Q   -0.021034\n",
       "24_Q    0.000000\n",
       "25_Q   -0.006302\n",
       "26_Q    0.040296\n",
       "27_Q    0.000000\n",
       "28_Q   -0.006482\n",
       "29_Q   -0.021500\n",
       "Name: 106, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuj7JFR-HAd_",
   "metadata": {
    "id": "fuj7JFR-HAd_"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential # Used to build model\n",
    "from keras.layers import Dense # Type of layer\n",
    "from keras.optimizers import Adam # Optimization technique\n",
    "from keras.layers import Dropout # For tuning the neural network\n",
    "from keras import regularizers # For regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nBFuhCL-FNH2",
   "metadata": {
    "id": "nBFuhCL-FNH2"
   },
   "outputs": [],
   "source": [
    "#initializing neural network\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(num_bus*2, input_dim=num_bus*2, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model1.add(Dense(num_bus*2, kernel_initializer='normal', kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "# model1.add(Dense(2, activation='softmax')) #in the output we have two neurons as this is the categorical model\n",
    "# compile model\n",
    "adam = Adam(lr=0.001)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HiXWEg9kG8BZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1243,
     "status": "ok",
     "timestamp": 1614926763646,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "HiXWEg9kG8BZ",
    "outputId": "15d0d359-f28d-45ba-88ae-433c2e04cd83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                3660      \n",
      "=================================================================\n",
      "Total params: 7,320\n",
      "Trainable params: 7,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OUaHQIFLIs22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 553370,
     "status": "error",
     "timestamp": 1614928558529,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "OUaHQIFLIs22",
    "outputId": "ac0f2f90-795c-4141-bd16-e9578b8071dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5975 - accuracy: 0.1140 - val_loss: 128.5971 - val_accuracy: 0.0220\n",
      "Epoch 2/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5969 - accuracy: 0.1240 - val_loss: 128.5966 - val_accuracy: 0.3380\n",
      "Epoch 3/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5963 - accuracy: 0.1140 - val_loss: 128.5960 - val_accuracy: 0.5940\n",
      "Epoch 4/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5957 - accuracy: 0.1320 - val_loss: 128.5954 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5952 - accuracy: 0.1020 - val_loss: 128.5949 - val_accuracy: 0.0140\n",
      "Epoch 6/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5948 - accuracy: 0.1240 - val_loss: 128.5945 - val_accuracy: 0.0120\n",
      "Epoch 7/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5942 - accuracy: 0.1440 - val_loss: 128.5941 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5939 - accuracy: 0.1100 - val_loss: 128.5936 - val_accuracy: 0.0200\n",
      "Epoch 9/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5934 - accuracy: 0.1180 - val_loss: 128.5932 - val_accuracy: 0.1600\n",
      "Epoch 10/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5931 - accuracy: 0.1120 - val_loss: 128.5929 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5927 - accuracy: 0.1180 - val_loss: 128.5926 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5907 - accuracy: 0.0760 - val_loss: 128.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5921 - accuracy: 0.1500 - val_loss: 128.5919 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5918 - accuracy: 0.1260 - val_loss: 128.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5916 - accuracy: 0.1140 - val_loss: 128.5915 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5915 - accuracy: 0.1320 - val_loss: 128.5913 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5913 - accuracy: 0.1220 - val_loss: 128.5912 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5910 - accuracy: 0.0860 - val_loss: 128.5910 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5909 - accuracy: 0.1380 - val_loss: 128.5909 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5908 - accuracy: 0.0900 - val_loss: 128.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5907 - accuracy: 0.0580 - val_loss: 128.5907 - val_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5907 - accuracy: 0.0620 - val_loss: 128.5907 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5906 - accuracy: 0.0500 - val_loss: 128.5906 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.0660 - val_loss: 128.5906 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.0260 - val_loss: 128.5905 - val_accuracy: 0.9880\n",
      "Epoch 26/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.0640 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.0480 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.0480 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.0200 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.0180 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0060 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0020 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0060 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0020 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.0140 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0060 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5905 - accuracy: 0.0040 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.0080 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.0020 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0160 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0100 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0160 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.0080 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.0160 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0180 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0200 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0160 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0160 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.0220 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0200 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.0260 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0200 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.0120 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0080 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.0220 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0160 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0220 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0100 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0180 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0040 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0120 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0040 - val_loss: 128.5905 - val_accuracy: 0.1180\n",
      "Epoch 63/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0100 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0140 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0020 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0060 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0040 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0120 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0120 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.0100 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0180 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0060 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0100 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0040 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0140 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.0060 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0120 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0140 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0120 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0280 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.0380 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0320 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0420 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0600 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.0560 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.0820 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.1940 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5903 - accuracy: 0.1860 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2280 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3260 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3440 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.2920 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2240 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5903 - accuracy: 0.1360 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.1200 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.1360 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.1640 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.1300 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.2000 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.1260 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5903 - accuracy: 0.1720 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.2240 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.1940 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5905 - accuracy: 0.2080 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2140 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2100 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.1800 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.1740 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.2740 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.2200 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.2120 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2320 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2380 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.2360 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.2920 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3400 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.2940 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.2660 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.2740 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.2700 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2620 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.2680 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.2540 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.2940 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2700 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2500 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.2860 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.2560 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5903 - accuracy: 0.3060 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.3300 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3220 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3300 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.3600 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.2980 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5904 - accuracy: 0.2860 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3020 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.2900 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3800 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.4100 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.4300 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.4320 - val_loss: 128.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3600 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3620 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.3880 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5905 - accuracy: 0.4840 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4480 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4280 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.4100 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.3600 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3720 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.3740 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4660 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3860 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.3640 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3080 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.3500 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.4260 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3140 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3680 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3980 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.3880 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3400 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3980 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.3320 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.5160 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.4320 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.5340 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.5140 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.5460 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.5800 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4900 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4820 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4480 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4380 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.4220 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4220 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.4940 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.5680 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.5340 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.4440 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.5220 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.5160 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.4820 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.4400 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.4760 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 128.5903 - accuracy: 0.5480 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.6800 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.9780 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.6840 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 0.6820 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 0.9920 - val_loss: 128.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 0.8840 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 0.8340 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 128.5903 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "500/500 [==============================] - 2s 5ms/step - loss: 128.5904 - accuracy: 1.0000 - val_loss: 128.5904 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "497/500 [============================>.] - ETA: 0s - loss: 128.5824 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-94f340fc752a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model1(categorical one) to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Use cached evaluation data only when it's called in `Model.fit`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       if (getattr(self, '_fit_frame', None) is not None\n\u001b[0;32m-> 1349\u001b[0;31m           \u001b[0;32mand\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m           and getattr(self, '_eval_data_handler', None) is not None):\n\u001b[1;32m   1351\u001b[0m         \u001b[0mdata_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_data_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_inspect.py\u001b[0m in \u001b[0;36mcurrentframe\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;34m\"\"\"TFDecorator-aware replacement for inspect.currentframe.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m     \u001b[0;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1513\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{!r} is not a frame or traceback object'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;31m# or it is in the linecache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0;31m# Update the filename to module name cache and check yet again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;31m# Copy sys.modules in order to cope with changes while iterating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the model1(categorical one) to the training data\n",
    "history1=model1.fit(X, Y, validation_data=(X, Y),epochs=500, batch_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HnS08qmxJOi-",
   "metadata": {
    "id": "HnS08qmxJOi-"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PNp1QEOJPmN-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1240,
     "status": "ok",
     "timestamp": 1614928574613,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "PNp1QEOJPmN-",
    "outputId": "98d0ef9d-68e0-4fdf-d4eb-b79204633ede"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 60)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stmSC41ePYmM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "executionInfo": {
     "elapsed": 991,
     "status": "error",
     "timestamp": 1614938916570,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "stmSC41ePYmM",
    "outputId": "87e4cee9-0556-4261-ae82-4902e545d4b2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-47ffb7f3a48a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nlFwPayoPukS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6245,
     "status": "ok",
     "timestamp": 1614938946902,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "nlFwPayoPukS",
    "outputId": "6e52dc65-e86e-4fba-b2f7-b39dd1f1295a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                1860      \n",
      "=================================================================\n",
      "Total params: 7,350\n",
      "Trainable params: 7,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(num_bus*2, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(num_bus, kernel_initializer='normal',activation='relu'))\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "# NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(num_bus*2, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_percentage_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zOOuSds4QOdo",
   "metadata": {
    "id": "zOOuSds4QOdo"
   },
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CrhD3I06QlsR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40680,
     "status": "ok",
     "timestamp": 1614938994440,
     "user": {
      "displayName": "GOPAL JAIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjBWLalC1TXnFY7M42yBOhJVy-VTt2oWCF8kv1rUw=s64",
      "userId": "07748152305612185938"
     },
     "user_tz": -330
    },
    "id": "CrhD3I06QlsR",
    "outputId": "c7c192bc-3c7c-4870-8892-01a3f88c2f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "13/13 [==============================] - 3s 25ms/step - loss: 20540.6669 - mean_absolute_percentage_error: 20540.6669 - val_loss: 14215.9033 - val_mean_absolute_percentage_error: 14215.9033\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 14215.90332, saving model to Weights-001--14215.90332.hdf5\n",
      "Epoch 2/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 10537.1235 - mean_absolute_percentage_error: 10537.1235 - val_loss: 6201.9492 - val_mean_absolute_percentage_error: 6201.9492\n",
      "\n",
      "Epoch 00002: val_loss improved from 14215.90332 to 6201.94922, saving model to Weights-002--6201.94922.hdf5\n",
      "Epoch 3/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3665.7824 - mean_absolute_percentage_error: 3665.7824 - val_loss: 1172.0448 - val_mean_absolute_percentage_error: 1172.0448\n",
      "\n",
      "Epoch 00003: val_loss improved from 6201.94922 to 1172.04480, saving model to Weights-003--1172.04480.hdf5\n",
      "Epoch 4/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1285.4045 - mean_absolute_percentage_error: 1285.4045 - val_loss: 920.8722 - val_mean_absolute_percentage_error: 920.8722\n",
      "\n",
      "Epoch 00004: val_loss improved from 1172.04480 to 920.87219, saving model to Weights-004--920.87219.hdf5\n",
      "Epoch 5/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1252.2602 - mean_absolute_percentage_error: 1252.2602 - val_loss: 7356.0454 - val_mean_absolute_percentage_error: 7356.0454\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 920.87219\n",
      "Epoch 6/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 6216.9057 - mean_absolute_percentage_error: 6216.9057 - val_loss: 756.6749 - val_mean_absolute_percentage_error: 756.6749\n",
      "\n",
      "Epoch 00006: val_loss improved from 920.87219 to 756.67487, saving model to Weights-006--756.67487.hdf5\n",
      "Epoch 7/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2269.6192 - mean_absolute_percentage_error: 2269.6192 - val_loss: 2224.8250 - val_mean_absolute_percentage_error: 2224.8250\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 756.67487\n",
      "Epoch 8/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2657.7116 - mean_absolute_percentage_error: 2657.7116 - val_loss: 3061.4675 - val_mean_absolute_percentage_error: 3061.4675\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 756.67487\n",
      "Epoch 9/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2618.4922 - mean_absolute_percentage_error: 2618.4922 - val_loss: 2467.9321 - val_mean_absolute_percentage_error: 2467.9321\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 756.67487\n",
      "Epoch 10/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2453.3677 - mean_absolute_percentage_error: 2453.3677 - val_loss: 2886.8018 - val_mean_absolute_percentage_error: 2886.8018\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 756.67487\n",
      "Epoch 11/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2529.2936 - mean_absolute_percentage_error: 2529.2936 - val_loss: 2121.3098 - val_mean_absolute_percentage_error: 2121.3098\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 756.67487\n",
      "Epoch 12/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2378.8948 - mean_absolute_percentage_error: 2378.8948 - val_loss: 2445.7256 - val_mean_absolute_percentage_error: 2445.7256\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 756.67487\n",
      "Epoch 13/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2450.6056 - mean_absolute_percentage_error: 2450.6056 - val_loss: 1724.0824 - val_mean_absolute_percentage_error: 1724.0824\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 756.67487\n",
      "Epoch 14/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2106.6439 - mean_absolute_percentage_error: 2106.6439 - val_loss: 2161.0002 - val_mean_absolute_percentage_error: 2161.0002\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 756.67487\n",
      "Epoch 15/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2242.6617 - mean_absolute_percentage_error: 2242.6617 - val_loss: 2316.5220 - val_mean_absolute_percentage_error: 2316.5220\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 756.67487\n",
      "Epoch 16/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2259.5053 - mean_absolute_percentage_error: 2259.5053 - val_loss: 2418.5269 - val_mean_absolute_percentage_error: 2418.5269\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 756.67487\n",
      "Epoch 17/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2068.0852 - mean_absolute_percentage_error: 2068.0852 - val_loss: 1570.0492 - val_mean_absolute_percentage_error: 1570.0492\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 756.67487\n",
      "Epoch 18/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1705.7036 - mean_absolute_percentage_error: 1705.7036 - val_loss: 1583.2585 - val_mean_absolute_percentage_error: 1583.2585\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 756.67487\n",
      "Epoch 19/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1656.4995 - mean_absolute_percentage_error: 1656.4995 - val_loss: 1634.0323 - val_mean_absolute_percentage_error: 1634.0323\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 756.67487\n",
      "Epoch 20/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1847.8680 - mean_absolute_percentage_error: 1847.8680 - val_loss: 1040.9502 - val_mean_absolute_percentage_error: 1040.9502\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 756.67487\n",
      "Epoch 21/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2086.1103 - mean_absolute_percentage_error: 2086.1103 - val_loss: 656.1028 - val_mean_absolute_percentage_error: 656.1028\n",
      "\n",
      "Epoch 00021: val_loss improved from 756.67487 to 656.10278, saving model to Weights-021--656.10278.hdf5\n",
      "Epoch 22/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1827.8399 - mean_absolute_percentage_error: 1827.8399 - val_loss: 1700.4827 - val_mean_absolute_percentage_error: 1700.4827\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 656.10278\n",
      "Epoch 23/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1801.9135 - mean_absolute_percentage_error: 1801.9135 - val_loss: 1604.0913 - val_mean_absolute_percentage_error: 1604.0913\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 656.10278\n",
      "Epoch 24/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1822.5046 - mean_absolute_percentage_error: 1822.5046 - val_loss: 1906.4056 - val_mean_absolute_percentage_error: 1906.4056\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 656.10278\n",
      "Epoch 25/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1768.5105 - mean_absolute_percentage_error: 1768.5105 - val_loss: 2056.0906 - val_mean_absolute_percentage_error: 2056.0906\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 656.10278\n",
      "Epoch 26/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1803.8847 - mean_absolute_percentage_error: 1803.8847 - val_loss: 2744.6843 - val_mean_absolute_percentage_error: 2744.6843\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 656.10278\n",
      "Epoch 27/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2377.8763 - mean_absolute_percentage_error: 2377.8763 - val_loss: 612.2220 - val_mean_absolute_percentage_error: 612.2220\n",
      "\n",
      "Epoch 00027: val_loss improved from 656.10278 to 612.22205, saving model to Weights-027--612.22205.hdf5\n",
      "Epoch 28/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1361.5653 - mean_absolute_percentage_error: 1361.5653 - val_loss: 2594.4890 - val_mean_absolute_percentage_error: 2594.4890\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 612.22205\n",
      "Epoch 29/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1874.6158 - mean_absolute_percentage_error: 1874.6158 - val_loss: 2092.9517 - val_mean_absolute_percentage_error: 2092.9517\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 612.22205\n",
      "Epoch 30/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1362.0719 - mean_absolute_percentage_error: 1362.0719 - val_loss: 704.2914 - val_mean_absolute_percentage_error: 704.2914\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 612.22205\n",
      "Epoch 31/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2602.6039 - mean_absolute_percentage_error: 2602.6039 - val_loss: 3453.7554 - val_mean_absolute_percentage_error: 3453.7554\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 612.22205\n",
      "Epoch 32/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2361.9362 - mean_absolute_percentage_error: 2361.9362 - val_loss: 2472.4932 - val_mean_absolute_percentage_error: 2472.4932\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 612.22205\n",
      "Epoch 33/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1889.0707 - mean_absolute_percentage_error: 1889.0707 - val_loss: 1810.0800 - val_mean_absolute_percentage_error: 1810.0800\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 612.22205\n",
      "Epoch 34/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1786.4414 - mean_absolute_percentage_error: 1786.4414 - val_loss: 695.7960 - val_mean_absolute_percentage_error: 695.7960\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 612.22205\n",
      "Epoch 35/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1397.2423 - mean_absolute_percentage_error: 1397.2423 - val_loss: 930.7797 - val_mean_absolute_percentage_error: 930.7797\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 612.22205\n",
      "Epoch 36/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1611.9386 - mean_absolute_percentage_error: 1611.9386 - val_loss: 2981.9800 - val_mean_absolute_percentage_error: 2981.9800\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 612.22205\n",
      "Epoch 37/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2912.7635 - mean_absolute_percentage_error: 2912.7635 - val_loss: 1869.8801 - val_mean_absolute_percentage_error: 1869.8801\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 612.22205\n",
      "Epoch 38/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1586.0359 - mean_absolute_percentage_error: 1586.0359 - val_loss: 2151.2356 - val_mean_absolute_percentage_error: 2151.2356\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 612.22205\n",
      "Epoch 39/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1714.3861 - mean_absolute_percentage_error: 1714.3861 - val_loss: 1410.4008 - val_mean_absolute_percentage_error: 1410.4008\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 612.22205\n",
      "Epoch 40/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1599.4178 - mean_absolute_percentage_error: 1599.4178 - val_loss: 1754.8218 - val_mean_absolute_percentage_error: 1754.8218\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 612.22205\n",
      "Epoch 41/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1638.9043 - mean_absolute_percentage_error: 1638.9043 - val_loss: 1844.7679 - val_mean_absolute_percentage_error: 1844.7679\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 612.22205\n",
      "Epoch 42/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1585.4684 - mean_absolute_percentage_error: 1585.4684 - val_loss: 1216.7844 - val_mean_absolute_percentage_error: 1216.7844\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 612.22205\n",
      "Epoch 43/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1454.2408 - mean_absolute_percentage_error: 1454.2408 - val_loss: 1657.9219 - val_mean_absolute_percentage_error: 1657.9219\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 612.22205\n",
      "Epoch 44/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1588.2764 - mean_absolute_percentage_error: 1588.2764 - val_loss: 1409.9031 - val_mean_absolute_percentage_error: 1409.9031\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 612.22205\n",
      "Epoch 45/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1529.9546 - mean_absolute_percentage_error: 1529.9546 - val_loss: 1685.0537 - val_mean_absolute_percentage_error: 1685.0537\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 612.22205\n",
      "Epoch 46/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1503.9967 - mean_absolute_percentage_error: 1503.9967 - val_loss: 1877.7048 - val_mean_absolute_percentage_error: 1877.7048\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 612.22205\n",
      "Epoch 47/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1608.0511 - mean_absolute_percentage_error: 1608.0511 - val_loss: 1792.5999 - val_mean_absolute_percentage_error: 1792.5999\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 612.22205\n",
      "Epoch 48/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1539.4577 - mean_absolute_percentage_error: 1539.4577 - val_loss: 1808.2417 - val_mean_absolute_percentage_error: 1808.2417\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 612.22205\n",
      "Epoch 49/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2622.7732 - mean_absolute_percentage_error: 2622.7732 - val_loss: 3716.4160 - val_mean_absolute_percentage_error: 3716.4160\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 612.22205\n",
      "Epoch 50/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4504.3859 - mean_absolute_percentage_error: 4504.3859 - val_loss: 4114.0532 - val_mean_absolute_percentage_error: 4114.0532\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 612.22205\n",
      "Epoch 51/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 3593.9118 - mean_absolute_percentage_error: 3593.9118 - val_loss: 5213.4941 - val_mean_absolute_percentage_error: 5213.4941\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 612.22205\n",
      "Epoch 52/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4091.7082 - mean_absolute_percentage_error: 4091.7082 - val_loss: 2462.3391 - val_mean_absolute_percentage_error: 2462.3391\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 612.22205\n",
      "Epoch 53/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2503.6098 - mean_absolute_percentage_error: 2503.6098 - val_loss: 2646.6392 - val_mean_absolute_percentage_error: 2646.6392\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 612.22205\n",
      "Epoch 54/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2244.0074 - mean_absolute_percentage_error: 2244.0074 - val_loss: 1867.4240 - val_mean_absolute_percentage_error: 1867.4240\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 612.22205\n",
      "Epoch 55/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1564.1590 - mean_absolute_percentage_error: 1564.1590 - val_loss: 1936.9320 - val_mean_absolute_percentage_error: 1936.9320\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 612.22205\n",
      "Epoch 56/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1555.1937 - mean_absolute_percentage_error: 1555.1937 - val_loss: 886.2500 - val_mean_absolute_percentage_error: 886.2500\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 612.22205\n",
      "Epoch 57/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1353.4318 - mean_absolute_percentage_error: 1353.4318 - val_loss: 1173.3606 - val_mean_absolute_percentage_error: 1173.3606\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 612.22205\n",
      "Epoch 58/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 768.2288 - mean_absolute_percentage_error: 768.2288 - val_loss: 550.3799 - val_mean_absolute_percentage_error: 550.3799\n",
      "\n",
      "Epoch 00058: val_loss improved from 612.22205 to 550.37994, saving model to Weights-058--550.37994.hdf5\n",
      "Epoch 59/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 629.3475 - mean_absolute_percentage_error: 629.3475 - val_loss: 4014.4055 - val_mean_absolute_percentage_error: 4014.4055\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 550.37994\n",
      "Epoch 60/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 3076.3818 - mean_absolute_percentage_error: 3076.3818 - val_loss: 1744.5409 - val_mean_absolute_percentage_error: 1744.5409\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 550.37994\n",
      "Epoch 61/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1165.5897 - mean_absolute_percentage_error: 1165.5897 - val_loss: 270.0305 - val_mean_absolute_percentage_error: 270.0305\n",
      "\n",
      "Epoch 00061: val_loss improved from 550.37994 to 270.03052, saving model to Weights-061--270.03052.hdf5\n",
      "Epoch 62/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1273.1506 - mean_absolute_percentage_error: 1273.1506 - val_loss: 2645.3618 - val_mean_absolute_percentage_error: 2645.3618\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 270.03052\n",
      "Epoch 63/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2831.7953 - mean_absolute_percentage_error: 2831.7953 - val_loss: 1083.8568 - val_mean_absolute_percentage_error: 1083.8568\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 270.03052\n",
      "Epoch 64/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1401.0282 - mean_absolute_percentage_error: 1401.0282 - val_loss: 5542.3027 - val_mean_absolute_percentage_error: 5542.3027\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 270.03052\n",
      "Epoch 65/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 4236.0852 - mean_absolute_percentage_error: 4236.0852 - val_loss: 271.4846 - val_mean_absolute_percentage_error: 271.4846\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 270.03052\n",
      "Epoch 66/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 936.3519 - mean_absolute_percentage_error: 936.3519 - val_loss: 1021.3696 - val_mean_absolute_percentage_error: 1021.3696\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 270.03052\n",
      "Epoch 67/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1305.3226 - mean_absolute_percentage_error: 1305.3226 - val_loss: 1809.5704 - val_mean_absolute_percentage_error: 1809.5704\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 270.03052\n",
      "Epoch 68/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1447.5881 - mean_absolute_percentage_error: 1447.5881 - val_loss: 970.5291 - val_mean_absolute_percentage_error: 970.5291\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 270.03052\n",
      "Epoch 69/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1270.4055 - mean_absolute_percentage_error: 1270.4055 - val_loss: 1809.1536 - val_mean_absolute_percentage_error: 1809.1536\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 270.03052\n",
      "Epoch 70/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1439.2127 - mean_absolute_percentage_error: 1439.2127 - val_loss: 994.3976 - val_mean_absolute_percentage_error: 994.3976\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 270.03052\n",
      "Epoch 71/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1285.8399 - mean_absolute_percentage_error: 1285.8399 - val_loss: 1272.8607 - val_mean_absolute_percentage_error: 1272.8607\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 270.03052\n",
      "Epoch 72/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1285.7690 - mean_absolute_percentage_error: 1285.7690 - val_loss: 930.2715 - val_mean_absolute_percentage_error: 930.2715\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 270.03052\n",
      "Epoch 73/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1241.4354 - mean_absolute_percentage_error: 1241.4354 - val_loss: 1637.1947 - val_mean_absolute_percentage_error: 1637.1947\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 270.03052\n",
      "Epoch 74/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1364.5454 - mean_absolute_percentage_error: 1364.5454 - val_loss: 673.4520 - val_mean_absolute_percentage_error: 673.4520\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 270.03052\n",
      "Epoch 75/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1405.2430 - mean_absolute_percentage_error: 1405.2430 - val_loss: 476.0076 - val_mean_absolute_percentage_error: 476.0076\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 270.03052\n",
      "Epoch 76/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1105.6161 - mean_absolute_percentage_error: 1105.6161 - val_loss: 854.2834 - val_mean_absolute_percentage_error: 854.2834\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 270.03052\n",
      "Epoch 77/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1167.3105 - mean_absolute_percentage_error: 1167.3105 - val_loss: 1078.0986 - val_mean_absolute_percentage_error: 1078.0986\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 270.03052\n",
      "Epoch 78/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1250.0707 - mean_absolute_percentage_error: 1250.0707 - val_loss: 1255.2850 - val_mean_absolute_percentage_error: 1255.2850\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 270.03052\n",
      "Epoch 79/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1222.3186 - mean_absolute_percentage_error: 1222.3186 - val_loss: 1106.2429 - val_mean_absolute_percentage_error: 1106.2429\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 270.03052\n",
      "Epoch 80/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1211.8656 - mean_absolute_percentage_error: 1211.8656 - val_loss: 1449.4547 - val_mean_absolute_percentage_error: 1449.4547\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 270.03052\n",
      "Epoch 81/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1297.3462 - mean_absolute_percentage_error: 1297.3462 - val_loss: 1263.8646 - val_mean_absolute_percentage_error: 1263.8646\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 270.03052\n",
      "Epoch 82/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1247.7244 - mean_absolute_percentage_error: 1247.7244 - val_loss: 1229.9128 - val_mean_absolute_percentage_error: 1229.9128\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 270.03052\n",
      "Epoch 83/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1206.4979 - mean_absolute_percentage_error: 1206.4979 - val_loss: 1076.4142 - val_mean_absolute_percentage_error: 1076.4142\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 270.03052\n",
      "Epoch 84/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1200.7080 - mean_absolute_percentage_error: 1200.7080 - val_loss: 1360.2689 - val_mean_absolute_percentage_error: 1360.2689\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 270.03052\n",
      "Epoch 85/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1259.7463 - mean_absolute_percentage_error: 1259.7463 - val_loss: 1223.6888 - val_mean_absolute_percentage_error: 1223.6888\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 270.03052\n",
      "Epoch 86/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1243.8961 - mean_absolute_percentage_error: 1243.8961 - val_loss: 1236.4966 - val_mean_absolute_percentage_error: 1236.4966\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 270.03052\n",
      "Epoch 87/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1207.2731 - mean_absolute_percentage_error: 1207.2731 - val_loss: 1108.8777 - val_mean_absolute_percentage_error: 1108.8777\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 270.03052\n",
      "Epoch 88/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1208.8503 - mean_absolute_percentage_error: 1208.8503 - val_loss: 1300.0925 - val_mean_absolute_percentage_error: 1300.0925\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 270.03052\n",
      "Epoch 89/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1248.5353 - mean_absolute_percentage_error: 1248.5353 - val_loss: 1200.8519 - val_mean_absolute_percentage_error: 1200.8519\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 270.03052\n",
      "Epoch 90/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1163.8921 - mean_absolute_percentage_error: 1163.8921 - val_loss: 1297.8857 - val_mean_absolute_percentage_error: 1297.8857\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 270.03052\n",
      "Epoch 91/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1168.6310 - mean_absolute_percentage_error: 1168.6310 - val_loss: 1234.9083 - val_mean_absolute_percentage_error: 1234.9083\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 270.03052\n",
      "Epoch 92/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1212.0884 - mean_absolute_percentage_error: 1212.0884 - val_loss: 1188.6703 - val_mean_absolute_percentage_error: 1188.6703\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 270.03052\n",
      "Epoch 93/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1208.0724 - mean_absolute_percentage_error: 1208.0724 - val_loss: 1071.0895 - val_mean_absolute_percentage_error: 1071.0895\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 270.03052\n",
      "Epoch 94/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1197.4350 - mean_absolute_percentage_error: 1197.4350 - val_loss: 1266.3209 - val_mean_absolute_percentage_error: 1266.3209\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 270.03052\n",
      "Epoch 95/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1171.3293 - mean_absolute_percentage_error: 1171.3293 - val_loss: 1225.0380 - val_mean_absolute_percentage_error: 1225.0380\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 270.03052\n",
      "Epoch 96/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1209.4550 - mean_absolute_percentage_error: 1209.4550 - val_loss: 1153.9518 - val_mean_absolute_percentage_error: 1153.9518\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 270.03052\n",
      "Epoch 97/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1188.6502 - mean_absolute_percentage_error: 1188.6502 - val_loss: 911.2801 - val_mean_absolute_percentage_error: 911.2801\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 270.03052\n",
      "Epoch 98/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1153.3586 - mean_absolute_percentage_error: 1153.3586 - val_loss: 1505.7527 - val_mean_absolute_percentage_error: 1505.7527\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 270.03052\n",
      "Epoch 99/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1236.9316 - mean_absolute_percentage_error: 1236.9316 - val_loss: 1374.3032 - val_mean_absolute_percentage_error: 1374.3032\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 270.03052\n",
      "Epoch 100/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1196.2646 - mean_absolute_percentage_error: 1196.2646 - val_loss: 840.3398 - val_mean_absolute_percentage_error: 840.3398\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 270.03052\n",
      "Epoch 101/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1103.1551 - mean_absolute_percentage_error: 1103.1551 - val_loss: 652.8749 - val_mean_absolute_percentage_error: 652.8749\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 270.03052\n",
      "Epoch 102/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1098.2606 - mean_absolute_percentage_error: 1098.2606 - val_loss: 1700.5876 - val_mean_absolute_percentage_error: 1700.5876\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 270.03052\n",
      "Epoch 103/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1295.9465 - mean_absolute_percentage_error: 1295.9465 - val_loss: 736.2950 - val_mean_absolute_percentage_error: 736.2950\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 270.03052\n",
      "Epoch 104/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1071.5617 - mean_absolute_percentage_error: 1071.5617 - val_loss: 490.6382 - val_mean_absolute_percentage_error: 490.6382\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 270.03052\n",
      "Epoch 105/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 571.1884 - mean_absolute_percentage_error: 571.1884 - val_loss: 2704.9800 - val_mean_absolute_percentage_error: 2704.9800\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 270.03052\n",
      "Epoch 106/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2426.7535 - mean_absolute_percentage_error: 2426.7535 - val_loss: 3518.7546 - val_mean_absolute_percentage_error: 3518.7546\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 270.03052\n",
      "Epoch 107/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2310.6934 - mean_absolute_percentage_error: 2310.6934 - val_loss: 1221.1908 - val_mean_absolute_percentage_error: 1221.1908\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 270.03052\n",
      "Epoch 108/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1969.6311 - mean_absolute_percentage_error: 1969.6311 - val_loss: 2282.0586 - val_mean_absolute_percentage_error: 2282.0586\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 270.03052\n",
      "Epoch 109/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2206.1437 - mean_absolute_percentage_error: 2206.1437 - val_loss: 3044.9524 - val_mean_absolute_percentage_error: 3044.9524\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 270.03052\n",
      "Epoch 110/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2187.3269 - mean_absolute_percentage_error: 2187.3269 - val_loss: 1624.5267 - val_mean_absolute_percentage_error: 1624.5267\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 270.03052\n",
      "Epoch 111/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1923.9505 - mean_absolute_percentage_error: 1923.9505 - val_loss: 1736.4022 - val_mean_absolute_percentage_error: 1736.4022\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 270.03052\n",
      "Epoch 112/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1969.3413 - mean_absolute_percentage_error: 1969.3413 - val_loss: 2637.9875 - val_mean_absolute_percentage_error: 2637.9875\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 270.03052\n",
      "Epoch 113/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2035.7467 - mean_absolute_percentage_error: 2035.7467 - val_loss: 1359.1047 - val_mean_absolute_percentage_error: 1359.1047\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 270.03052\n",
      "Epoch 114/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1909.0125 - mean_absolute_percentage_error: 1909.0125 - val_loss: 1865.0856 - val_mean_absolute_percentage_error: 1865.0856\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 270.03052\n",
      "Epoch 115/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2043.1363 - mean_absolute_percentage_error: 2043.1363 - val_loss: 2632.5913 - val_mean_absolute_percentage_error: 2632.5913\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 270.03052\n",
      "Epoch 116/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2069.3966 - mean_absolute_percentage_error: 2069.3966 - val_loss: 1302.5148 - val_mean_absolute_percentage_error: 1302.5148\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 270.03052\n",
      "Epoch 117/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1884.7513 - mean_absolute_percentage_error: 1884.7513 - val_loss: 1919.9849 - val_mean_absolute_percentage_error: 1919.9849\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 270.03052\n",
      "Epoch 118/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1963.5543 - mean_absolute_percentage_error: 1963.5543 - val_loss: 2811.5322 - val_mean_absolute_percentage_error: 2811.5322\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 270.03052\n",
      "Epoch 119/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 2043.7319 - mean_absolute_percentage_error: 2043.7319 - val_loss: 1655.8774 - val_mean_absolute_percentage_error: 1655.8774\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 270.03052\n",
      "Epoch 120/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2038.6028 - mean_absolute_percentage_error: 2038.6028 - val_loss: 3325.3345 - val_mean_absolute_percentage_error: 3325.3345\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 270.03052\n",
      "Epoch 121/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2457.9105 - mean_absolute_percentage_error: 2457.9105 - val_loss: 2731.1990 - val_mean_absolute_percentage_error: 2731.1990\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 270.03052\n",
      "Epoch 122/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2041.3693 - mean_absolute_percentage_error: 2041.3693 - val_loss: 2038.4324 - val_mean_absolute_percentage_error: 2038.4324\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 270.03052\n",
      "Epoch 123/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1807.0624 - mean_absolute_percentage_error: 1807.0624 - val_loss: 1924.3689 - val_mean_absolute_percentage_error: 1924.3689\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 270.03052\n",
      "Epoch 124/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1964.0277 - mean_absolute_percentage_error: 1964.0277 - val_loss: 3121.0476 - val_mean_absolute_percentage_error: 3121.0476\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 270.03052\n",
      "Epoch 125/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2105.2421 - mean_absolute_percentage_error: 2105.2421 - val_loss: 1999.6985 - val_mean_absolute_percentage_error: 1999.6985\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 270.03052\n",
      "Epoch 126/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1790.9860 - mean_absolute_percentage_error: 1790.9860 - val_loss: 1051.1201 - val_mean_absolute_percentage_error: 1051.1201\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 270.03052\n",
      "Epoch 127/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1609.2334 - mean_absolute_percentage_error: 1609.2334 - val_loss: 3505.4233 - val_mean_absolute_percentage_error: 3505.4233\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 270.03052\n",
      "Epoch 128/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1817.7496 - mean_absolute_percentage_error: 1817.7496 - val_loss: 493.1582 - val_mean_absolute_percentage_error: 493.1582\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 270.03052\n",
      "Epoch 129/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 815.9260 - mean_absolute_percentage_error: 815.9260 - val_loss: 750.0364 - val_mean_absolute_percentage_error: 750.0364\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 270.03052\n",
      "Epoch 130/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1160.6989 - mean_absolute_percentage_error: 1160.6989 - val_loss: 572.5772 - val_mean_absolute_percentage_error: 572.5772\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 270.03052\n",
      "Epoch 131/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1307.2410 - mean_absolute_percentage_error: 1307.2410 - val_loss: 3081.7307 - val_mean_absolute_percentage_error: 3081.7307\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 270.03052\n",
      "Epoch 132/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 2064.0364 - mean_absolute_percentage_error: 2064.0364 - val_loss: 1485.3472 - val_mean_absolute_percentage_error: 1485.3472\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 270.03052\n",
      "Epoch 133/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1771.7185 - mean_absolute_percentage_error: 1771.7185 - val_loss: 1680.4576 - val_mean_absolute_percentage_error: 1680.4576\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 270.03052\n",
      "Epoch 134/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1841.4954 - mean_absolute_percentage_error: 1841.4954 - val_loss: 2505.2351 - val_mean_absolute_percentage_error: 2505.2351\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 270.03052\n",
      "Epoch 135/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1945.8408 - mean_absolute_percentage_error: 1945.8408 - val_loss: 1204.2744 - val_mean_absolute_percentage_error: 1204.2744\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 270.03052\n",
      "Epoch 136/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1769.8537 - mean_absolute_percentage_error: 1769.8537 - val_loss: 2037.5596 - val_mean_absolute_percentage_error: 2037.5596\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 270.03052\n",
      "Epoch 137/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1983.9353 - mean_absolute_percentage_error: 1983.9353 - val_loss: 3067.2676 - val_mean_absolute_percentage_error: 3067.2676\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 270.03052\n",
      "Epoch 138/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1984.0482 - mean_absolute_percentage_error: 1984.0482 - val_loss: 1735.3059 - val_mean_absolute_percentage_error: 1735.3059\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 270.03052\n",
      "Epoch 139/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1767.1895 - mean_absolute_percentage_error: 1767.1895 - val_loss: 1762.7467 - val_mean_absolute_percentage_error: 1762.7467\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 270.03052\n",
      "Epoch 140/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1839.6613 - mean_absolute_percentage_error: 1839.6613 - val_loss: 2571.8201 - val_mean_absolute_percentage_error: 2571.8201\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 270.03052\n",
      "Epoch 141/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1912.1613 - mean_absolute_percentage_error: 1912.1613 - val_loss: 1251.3176 - val_mean_absolute_percentage_error: 1251.3176\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 270.03052\n",
      "Epoch 142/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1662.2940 - mean_absolute_percentage_error: 1662.2940 - val_loss: 1758.5787 - val_mean_absolute_percentage_error: 1758.5787\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 270.03052\n",
      "Epoch 143/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1833.2191 - mean_absolute_percentage_error: 1833.2191 - val_loss: 2565.6604 - val_mean_absolute_percentage_error: 2565.6604\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 270.03052\n",
      "Epoch 144/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1869.0560 - mean_absolute_percentage_error: 1869.0560 - val_loss: 1483.0291 - val_mean_absolute_percentage_error: 1483.0291\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 270.03052\n",
      "Epoch 145/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1647.6272 - mean_absolute_percentage_error: 1647.6272 - val_loss: 1372.1086 - val_mean_absolute_percentage_error: 1372.1086\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 270.03052\n",
      "Epoch 146/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1690.5453 - mean_absolute_percentage_error: 1690.5453 - val_loss: 2081.6855 - val_mean_absolute_percentage_error: 2081.6855\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 270.03052\n",
      "Epoch 147/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1748.7840 - mean_absolute_percentage_error: 1748.7840 - val_loss: 854.2848 - val_mean_absolute_percentage_error: 854.2848\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 270.03052\n",
      "Epoch 148/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1646.3176 - mean_absolute_percentage_error: 1646.3176 - val_loss: 2065.7236 - val_mean_absolute_percentage_error: 2065.7236\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 270.03052\n",
      "Epoch 149/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1872.0542 - mean_absolute_percentage_error: 1872.0542 - val_loss: 2779.1831 - val_mean_absolute_percentage_error: 2779.1831\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 270.03052\n",
      "Epoch 150/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1887.4852 - mean_absolute_percentage_error: 1887.4852 - val_loss: 1697.2610 - val_mean_absolute_percentage_error: 1697.2610\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 270.03052\n",
      "Epoch 151/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1640.6721 - mean_absolute_percentage_error: 1640.6721 - val_loss: 1128.0817 - val_mean_absolute_percentage_error: 1128.0817\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 270.03052\n",
      "Epoch 152/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1593.4620 - mean_absolute_percentage_error: 1593.4620 - val_loss: 1808.1658 - val_mean_absolute_percentage_error: 1808.1658\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 270.03052\n",
      "Epoch 153/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1708.9235 - mean_absolute_percentage_error: 1708.9235 - val_loss: 697.1851 - val_mean_absolute_percentage_error: 697.1851\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 270.03052\n",
      "Epoch 154/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1661.3329 - mean_absolute_percentage_error: 1661.3329 - val_loss: 2187.9326 - val_mean_absolute_percentage_error: 2187.9326\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 270.03052\n",
      "Epoch 155/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1919.1433 - mean_absolute_percentage_error: 1919.1433 - val_loss: 2929.3726 - val_mean_absolute_percentage_error: 2929.3726\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 270.03052\n",
      "Epoch 156/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1902.5340 - mean_absolute_percentage_error: 1902.5340 - val_loss: 1837.5884 - val_mean_absolute_percentage_error: 1837.5884\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 270.03052\n",
      "Epoch 157/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1599.4958 - mean_absolute_percentage_error: 1599.4958 - val_loss: 956.4531 - val_mean_absolute_percentage_error: 956.4531\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 270.03052\n",
      "Epoch 158/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1522.5885 - mean_absolute_percentage_error: 1522.5885 - val_loss: 1642.9312 - val_mean_absolute_percentage_error: 1642.9312\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 270.03052\n",
      "Epoch 159/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1644.1130 - mean_absolute_percentage_error: 1644.1130 - val_loss: 518.8279 - val_mean_absolute_percentage_error: 518.8279\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 270.03052\n",
      "Epoch 160/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1611.5124 - mean_absolute_percentage_error: 1611.5124 - val_loss: 2303.3865 - val_mean_absolute_percentage_error: 2303.3865\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 270.03052\n",
      "Epoch 161/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1944.1086 - mean_absolute_percentage_error: 1944.1086 - val_loss: 3072.4854 - val_mean_absolute_percentage_error: 3072.4854\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 270.03052\n",
      "Epoch 162/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1926.1045 - mean_absolute_percentage_error: 1926.1045 - val_loss: 2003.7163 - val_mean_absolute_percentage_error: 2003.7163\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 270.03052\n",
      "Epoch 163/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1582.2546 - mean_absolute_percentage_error: 1582.2546 - val_loss: 787.0909 - val_mean_absolute_percentage_error: 787.0909\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 270.03052\n",
      "Epoch 164/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1459.9611 - mean_absolute_percentage_error: 1459.9611 - val_loss: 1545.8782 - val_mean_absolute_percentage_error: 1545.8782\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 270.03052\n",
      "Epoch 165/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1601.0154 - mean_absolute_percentage_error: 1601.0154 - val_loss: 1141.5756 - val_mean_absolute_percentage_error: 1141.5756\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 270.03052\n",
      "Epoch 166/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1590.4516 - mean_absolute_percentage_error: 1590.4516 - val_loss: 1427.5498 - val_mean_absolute_percentage_error: 1427.5498\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 270.03052\n",
      "Epoch 167/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1660.3704 - mean_absolute_percentage_error: 1660.3704 - val_loss: 2113.3125 - val_mean_absolute_percentage_error: 2113.3125\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 270.03052\n",
      "Epoch 168/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1749.0810 - mean_absolute_percentage_error: 1749.0810 - val_loss: 1021.5547 - val_mean_absolute_percentage_error: 1021.5547\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 270.03052\n",
      "Epoch 169/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1603.8676 - mean_absolute_percentage_error: 1603.8676 - val_loss: 1726.6539 - val_mean_absolute_percentage_error: 1726.6539\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 270.03052\n",
      "Epoch 170/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1736.7458 - mean_absolute_percentage_error: 1736.7458 - val_loss: 2443.9316 - val_mean_absolute_percentage_error: 2443.9316\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 270.03052\n",
      "Epoch 171/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1800.4162 - mean_absolute_percentage_error: 1800.4162 - val_loss: 1322.8278 - val_mean_absolute_percentage_error: 1322.8278\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 270.03052\n",
      "Epoch 172/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1581.8611 - mean_absolute_percentage_error: 1581.8611 - val_loss: 1454.9756 - val_mean_absolute_percentage_error: 1454.9756\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 270.03052\n",
      "Epoch 173/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1666.7115 - mean_absolute_percentage_error: 1666.7115 - val_loss: 2198.2463 - val_mean_absolute_percentage_error: 2198.2463\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 270.03052\n",
      "Epoch 174/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1739.4434 - mean_absolute_percentage_error: 1739.4434 - val_loss: 1125.6871 - val_mean_absolute_percentage_error: 1125.6871\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 270.03052\n",
      "Epoch 175/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1592.6691 - mean_absolute_percentage_error: 1592.6691 - val_loss: 1600.5771 - val_mean_absolute_percentage_error: 1600.5771\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 270.03052\n",
      "Epoch 176/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1704.0280 - mean_absolute_percentage_error: 1704.0280 - val_loss: 2285.3647 - val_mean_absolute_percentage_error: 2285.3647\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 270.03052\n",
      "Epoch 177/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1765.4136 - mean_absolute_percentage_error: 1765.4136 - val_loss: 1156.3406 - val_mean_absolute_percentage_error: 1156.3406\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 270.03052\n",
      "Epoch 178/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1586.4966 - mean_absolute_percentage_error: 1586.4966 - val_loss: 1613.5922 - val_mean_absolute_percentage_error: 1613.5922\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 270.03052\n",
      "Epoch 179/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1706.8499 - mean_absolute_percentage_error: 1706.8499 - val_loss: 2343.5393 - val_mean_absolute_percentage_error: 2343.5393\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 270.03052\n",
      "Epoch 180/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1749.6919 - mean_absolute_percentage_error: 1749.6919 - val_loss: 1270.5671 - val_mean_absolute_percentage_error: 1270.5671\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 270.03052\n",
      "Epoch 181/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1565.4836 - mean_absolute_percentage_error: 1565.4836 - val_loss: 1449.5437 - val_mean_absolute_percentage_error: 1449.5437\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 270.03052\n",
      "Epoch 182/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1644.0559 - mean_absolute_percentage_error: 1644.0559 - val_loss: 2140.1597 - val_mean_absolute_percentage_error: 2140.1597\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 270.03052\n",
      "Epoch 183/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1718.8682 - mean_absolute_percentage_error: 1718.8682 - val_loss: 1024.1561 - val_mean_absolute_percentage_error: 1024.1561\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 270.03052\n",
      "Epoch 184/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1569.6067 - mean_absolute_percentage_error: 1569.6067 - val_loss: 1722.4039 - val_mean_absolute_percentage_error: 1722.4039\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 270.03052\n",
      "Epoch 185/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1741.3798 - mean_absolute_percentage_error: 1741.3798 - val_loss: 2446.2788 - val_mean_absolute_percentage_error: 2446.2788\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 270.03052\n",
      "Epoch 186/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1778.3628 - mean_absolute_percentage_error: 1778.3628 - val_loss: 1375.9292 - val_mean_absolute_percentage_error: 1375.9292\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 270.03052\n",
      "Epoch 187/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1556.0823 - mean_absolute_percentage_error: 1556.0823 - val_loss: 1336.8171 - val_mean_absolute_percentage_error: 1336.8171\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 270.03052\n",
      "Epoch 188/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1606.9778 - mean_absolute_percentage_error: 1606.9778 - val_loss: 2027.3712 - val_mean_absolute_percentage_error: 2027.3712\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 270.03052\n",
      "Epoch 189/500\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1681.4138 - mean_absolute_percentage_error: 1681.4138 - val_loss: 926.5033 - val_mean_absolute_percentage_error: 926.5033\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 270.03052\n",
      "Epoch 190/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1571.3739 - mean_absolute_percentage_error: 1571.3739 - val_loss: 1809.3862 - val_mean_absolute_percentage_error: 1809.3862\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 270.03052\n",
      "Epoch 191/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1757.4669 - mean_absolute_percentage_error: 1757.4669 - val_loss: 2528.0466 - val_mean_absolute_percentage_error: 2528.0466\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 270.03052\n",
      "Epoch 192/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1780.2746 - mean_absolute_percentage_error: 1780.2746 - val_loss: 1461.0320 - val_mean_absolute_percentage_error: 1461.0320\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 270.03052\n",
      "Epoch 193/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1555.3341 - mean_absolute_percentage_error: 1555.3341 - val_loss: 1240.1508 - val_mean_absolute_percentage_error: 1240.1508\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 270.03052\n",
      "Epoch 194/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1563.4239 - mean_absolute_percentage_error: 1563.4239 - val_loss: 1929.8601 - val_mean_absolute_percentage_error: 1929.8601\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 270.03052\n",
      "Epoch 195/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1667.1350 - mean_absolute_percentage_error: 1667.1350 - val_loss: 835.2144 - val_mean_absolute_percentage_error: 835.2144\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 270.03052\n",
      "Epoch 196/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1565.4203 - mean_absolute_percentage_error: 1565.4203 - val_loss: 1893.1289 - val_mean_absolute_percentage_error: 1893.1289\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 270.03052\n",
      "Epoch 197/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1799.1037 - mean_absolute_percentage_error: 1799.1037 - val_loss: 2615.3428 - val_mean_absolute_percentage_error: 2615.3428\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 270.03052\n",
      "Epoch 198/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1799.9321 - mean_absolute_percentage_error: 1799.9321 - val_loss: 1560.0798 - val_mean_absolute_percentage_error: 1560.0798\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 270.03052\n",
      "Epoch 199/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1554.2801 - mean_absolute_percentage_error: 1554.2801 - val_loss: 1132.7861 - val_mean_absolute_percentage_error: 1132.7861\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 270.03052\n",
      "Epoch 200/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1539.0323 - mean_absolute_percentage_error: 1539.0323 - val_loss: 1823.2935 - val_mean_absolute_percentage_error: 1823.2935\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 270.03052\n",
      "Epoch 201/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1653.7140 - mean_absolute_percentage_error: 1653.7140 - val_loss: 734.0192 - val_mean_absolute_percentage_error: 734.0192\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 270.03052\n",
      "Epoch 202/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1561.4982 - mean_absolute_percentage_error: 1561.4982 - val_loss: 1980.9850 - val_mean_absolute_percentage_error: 1980.9850\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 270.03052\n",
      "Epoch 203/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1816.6441 - mean_absolute_percentage_error: 1816.6441 - val_loss: 2689.1755 - val_mean_absolute_percentage_error: 2689.1755\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 270.03052\n",
      "Epoch 204/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1799.2363 - mean_absolute_percentage_error: 1799.2363 - val_loss: 1623.5011 - val_mean_absolute_percentage_error: 1623.5011\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 270.03052\n",
      "Epoch 205/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1542.4637 - mean_absolute_percentage_error: 1542.4637 - val_loss: 1062.5228 - val_mean_absolute_percentage_error: 1062.5228\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 270.03052\n",
      "Epoch 206/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1506.1167 - mean_absolute_percentage_error: 1506.1167 - val_loss: 1746.4866 - val_mean_absolute_percentage_error: 1746.4866\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 270.03052\n",
      "Epoch 207/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1619.6839 - mean_absolute_percentage_error: 1619.6839 - val_loss: 663.5762 - val_mean_absolute_percentage_error: 663.5762\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 270.03052\n",
      "Epoch 208/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1557.3531 - mean_absolute_percentage_error: 1557.3531 - val_loss: 2039.5328 - val_mean_absolute_percentage_error: 2039.5328\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 270.03052\n",
      "Epoch 209/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1826.5282 - mean_absolute_percentage_error: 1826.5282 - val_loss: 2751.3425 - val_mean_absolute_percentage_error: 2751.3425\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 270.03052\n",
      "Epoch 210/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1806.6499 - mean_absolute_percentage_error: 1806.6499 - val_loss: 1691.6240 - val_mean_absolute_percentage_error: 1691.6240\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 270.03052\n",
      "Epoch 211/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1546.0158 - mean_absolute_percentage_error: 1546.0158 - val_loss: 983.2026 - val_mean_absolute_percentage_error: 983.2026\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 270.03052\n",
      "Epoch 212/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1468.7264 - mean_absolute_percentage_error: 1468.7264 - val_loss: 1666.8783 - val_mean_absolute_percentage_error: 1666.8783\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 270.03052\n",
      "Epoch 213/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1603.4861 - mean_absolute_percentage_error: 1603.4861 - val_loss: 589.3141 - val_mean_absolute_percentage_error: 589.3141\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 270.03052\n",
      "Epoch 214/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1552.0342 - mean_absolute_percentage_error: 1552.0342 - val_loss: 2098.7705 - val_mean_absolute_percentage_error: 2098.7705\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 270.03052\n",
      "Epoch 215/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1842.1965 - mean_absolute_percentage_error: 1842.1965 - val_loss: 2806.5300 - val_mean_absolute_percentage_error: 2806.5300\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 270.03052\n",
      "Epoch 216/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1810.2687 - mean_absolute_percentage_error: 1810.2687 - val_loss: 1743.6797 - val_mean_absolute_percentage_error: 1743.6797\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 270.03052\n",
      "Epoch 217/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1531.1195 - mean_absolute_percentage_error: 1531.1195 - val_loss: 930.0620 - val_mean_absolute_percentage_error: 930.0620\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 270.03052\n",
      "Epoch 218/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1446.7162 - mean_absolute_percentage_error: 1446.7162 - val_loss: 1617.3981 - val_mean_absolute_percentage_error: 1617.3981\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 270.03052\n",
      "Epoch 219/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1594.2320 - mean_absolute_percentage_error: 1594.2320 - val_loss: 544.0421 - val_mean_absolute_percentage_error: 544.0421\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 270.03052\n",
      "Epoch 220/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1555.5302 - mean_absolute_percentage_error: 1555.5302 - val_loss: 2144.3694 - val_mean_absolute_percentage_error: 2144.3694\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 270.03052\n",
      "Epoch 221/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1865.5922 - mean_absolute_percentage_error: 1865.5922 - val_loss: 2849.9004 - val_mean_absolute_percentage_error: 2849.9004\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 270.03052\n",
      "Epoch 222/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1824.5047 - mean_absolute_percentage_error: 1824.5047 - val_loss: 1805.3175 - val_mean_absolute_percentage_error: 1805.3175\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 270.03052\n",
      "Epoch 223/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1526.7302 - mean_absolute_percentage_error: 1526.7302 - val_loss: 838.9453 - val_mean_absolute_percentage_error: 838.9453\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 270.03052\n",
      "Epoch 224/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1411.4953 - mean_absolute_percentage_error: 1411.4953 - val_loss: 1477.2314 - val_mean_absolute_percentage_error: 1477.2314\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 270.03052\n",
      "Epoch 225/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1553.6901 - mean_absolute_percentage_error: 1553.6901 - val_loss: 417.0042 - val_mean_absolute_percentage_error: 417.0042\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 270.03052\n",
      "Epoch 226/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1538.4446 - mean_absolute_percentage_error: 1538.4446 - val_loss: 2257.6714 - val_mean_absolute_percentage_error: 2257.6714\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 270.03052\n",
      "Epoch 227/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1892.4650 - mean_absolute_percentage_error: 1892.4650 - val_loss: 2954.8313 - val_mean_absolute_percentage_error: 2954.8313\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 270.03052\n",
      "Epoch 228/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1830.0818 - mean_absolute_percentage_error: 1830.0818 - val_loss: 1896.3276 - val_mean_absolute_percentage_error: 1896.3276\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 270.03052\n",
      "Epoch 229/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1514.0066 - mean_absolute_percentage_error: 1514.0066 - val_loss: 760.8354 - val_mean_absolute_percentage_error: 760.8354\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 270.03052\n",
      "Epoch 230/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1378.3619 - mean_absolute_percentage_error: 1378.3619 - val_loss: 1449.7512 - val_mean_absolute_percentage_error: 1449.7512\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 270.03052\n",
      "Epoch 231/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1547.9704 - mean_absolute_percentage_error: 1547.9704 - val_loss: 394.3778 - val_mean_absolute_percentage_error: 394.3778\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 270.03052\n",
      "Epoch 232/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1537.1501 - mean_absolute_percentage_error: 1537.1501 - val_loss: 2262.8093 - val_mean_absolute_percentage_error: 2262.8093\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 270.03052\n",
      "Epoch 233/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1893.3877 - mean_absolute_percentage_error: 1893.3877 - val_loss: 2951.0393 - val_mean_absolute_percentage_error: 2951.0393\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 270.03052\n",
      "Epoch 234/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1829.8864 - mean_absolute_percentage_error: 1829.8864 - val_loss: 1895.0474 - val_mean_absolute_percentage_error: 1895.0474\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 270.03052\n",
      "Epoch 235/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1513.4069 - mean_absolute_percentage_error: 1513.4069 - val_loss: 759.2045 - val_mean_absolute_percentage_error: 759.2045\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 270.03052\n",
      "Epoch 236/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1377.4528 - mean_absolute_percentage_error: 1377.4528 - val_loss: 1446.1427 - val_mean_absolute_percentage_error: 1446.1427\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 270.03052\n",
      "Epoch 237/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1546.5027 - mean_absolute_percentage_error: 1546.5027 - val_loss: 388.2006 - val_mean_absolute_percentage_error: 388.2006\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 270.03052\n",
      "Epoch 238/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1535.4830 - mean_absolute_percentage_error: 1535.4830 - val_loss: 2265.2798 - val_mean_absolute_percentage_error: 2265.2798\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 270.03052\n",
      "Epoch 239/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1893.5671 - mean_absolute_percentage_error: 1893.5671 - val_loss: 2953.9009 - val_mean_absolute_percentage_error: 2953.9009\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 270.03052\n",
      "Epoch 240/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1829.1231 - mean_absolute_percentage_error: 1829.1231 - val_loss: 1899.5470 - val_mean_absolute_percentage_error: 1899.5470\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 270.03052\n",
      "Epoch 241/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1512.3834 - mean_absolute_percentage_error: 1512.3834 - val_loss: 751.1746 - val_mean_absolute_percentage_error: 751.1746\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 270.03052\n",
      "Epoch 242/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1374.4931 - mean_absolute_percentage_error: 1374.4931 - val_loss: 1439.5250 - val_mean_absolute_percentage_error: 1439.5250\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 270.03052\n",
      "Epoch 243/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1545.1921 - mean_absolute_percentage_error: 1545.1921 - val_loss: 383.2981 - val_mean_absolute_percentage_error: 383.2981\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 270.03052\n",
      "Epoch 244/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1535.2043 - mean_absolute_percentage_error: 1535.2043 - val_loss: 2268.7778 - val_mean_absolute_percentage_error: 2268.7778\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 270.03052\n",
      "Epoch 245/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1893.4772 - mean_absolute_percentage_error: 1893.4772 - val_loss: 2954.6890 - val_mean_absolute_percentage_error: 2954.6890\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 270.03052\n",
      "Epoch 246/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1828.4990 - mean_absolute_percentage_error: 1828.4990 - val_loss: 1896.1403 - val_mean_absolute_percentage_error: 1896.1403\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 270.03052\n",
      "Epoch 247/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1511.8579 - mean_absolute_percentage_error: 1511.8579 - val_loss: 754.8226 - val_mean_absolute_percentage_error: 754.8226\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 270.03052\n",
      "Epoch 248/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1375.6695 - mean_absolute_percentage_error: 1375.6695 - val_loss: 1442.9598 - val_mean_absolute_percentage_error: 1442.9598\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 270.03052\n",
      "Epoch 249/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1545.0537 - mean_absolute_percentage_error: 1545.0537 - val_loss: 386.2041 - val_mean_absolute_percentage_error: 386.2041\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 270.03052\n",
      "Epoch 250/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1534.5016 - mean_absolute_percentage_error: 1534.5016 - val_loss: 2265.8594 - val_mean_absolute_percentage_error: 2265.8594\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 270.03052\n",
      "Epoch 251/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1891.5937 - mean_absolute_percentage_error: 1891.5937 - val_loss: 2953.5454 - val_mean_absolute_percentage_error: 2953.5454\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 270.03052\n",
      "Epoch 252/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1828.9687 - mean_absolute_percentage_error: 1828.9687 - val_loss: 1899.5250 - val_mean_absolute_percentage_error: 1899.5250\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 270.03052\n",
      "Epoch 253/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1511.9158 - mean_absolute_percentage_error: 1511.9158 - val_loss: 753.7715 - val_mean_absolute_percentage_error: 753.7715\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 270.03052\n",
      "Epoch 254/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1374.5991 - mean_absolute_percentage_error: 1374.5991 - val_loss: 1444.2827 - val_mean_absolute_percentage_error: 1444.2827\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 270.03052\n",
      "Epoch 255/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1545.3388 - mean_absolute_percentage_error: 1545.3388 - val_loss: 386.0219 - val_mean_absolute_percentage_error: 386.0219\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 270.03052\n",
      "Epoch 256/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1534.7884 - mean_absolute_percentage_error: 1534.7884 - val_loss: 2266.9326 - val_mean_absolute_percentage_error: 2266.9326\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 270.03052\n",
      "Epoch 257/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1892.5973 - mean_absolute_percentage_error: 1892.5973 - val_loss: 2952.5234 - val_mean_absolute_percentage_error: 2952.5234\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 270.03052\n",
      "Epoch 258/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1827.9265 - mean_absolute_percentage_error: 1827.9265 - val_loss: 1899.5096 - val_mean_absolute_percentage_error: 1899.5096\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 270.03052\n",
      "Epoch 259/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1510.4545 - mean_absolute_percentage_error: 1510.4545 - val_loss: 749.2142 - val_mean_absolute_percentage_error: 749.2142\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 270.03052\n",
      "Epoch 260/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1373.4935 - mean_absolute_percentage_error: 1373.4935 - val_loss: 1438.4985 - val_mean_absolute_percentage_error: 1438.4985\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 270.03052\n",
      "Epoch 261/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1543.8762 - mean_absolute_percentage_error: 1543.8762 - val_loss: 382.2221 - val_mean_absolute_percentage_error: 382.2221\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 270.03052\n",
      "Epoch 262/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1533.8631 - mean_absolute_percentage_error: 1533.8631 - val_loss: 2268.4170 - val_mean_absolute_percentage_error: 2268.4170\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 270.03052\n",
      "Epoch 263/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1891.9765 - mean_absolute_percentage_error: 1891.9765 - val_loss: 2952.8340 - val_mean_absolute_percentage_error: 2952.8340\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 270.03052\n",
      "Epoch 264/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1827.1719 - mean_absolute_percentage_error: 1827.1719 - val_loss: 1897.8213 - val_mean_absolute_percentage_error: 1897.8213\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 270.03052\n",
      "Epoch 265/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1510.8220 - mean_absolute_percentage_error: 1510.8220 - val_loss: 749.4642 - val_mean_absolute_percentage_error: 749.4642\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 270.03052\n",
      "Epoch 266/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1372.1181 - mean_absolute_percentage_error: 1372.1181 - val_loss: 1438.9705 - val_mean_absolute_percentage_error: 1438.9705\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 270.03052\n",
      "Epoch 267/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1543.0090 - mean_absolute_percentage_error: 1543.0090 - val_loss: 385.9730 - val_mean_absolute_percentage_error: 385.9730\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 270.03052\n",
      "Epoch 268/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1533.4492 - mean_absolute_percentage_error: 1533.4492 - val_loss: 2259.2107 - val_mean_absolute_percentage_error: 2259.2107\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 270.03052\n",
      "Epoch 269/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1889.5953 - mean_absolute_percentage_error: 1889.5953 - val_loss: 2945.8486 - val_mean_absolute_percentage_error: 2945.8486\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 270.03052\n",
      "Epoch 270/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1825.6640 - mean_absolute_percentage_error: 1825.6640 - val_loss: 1890.7506 - val_mean_absolute_percentage_error: 1890.7506\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 270.03052\n",
      "Epoch 271/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1510.7782 - mean_absolute_percentage_error: 1510.7782 - val_loss: 757.3287 - val_mean_absolute_percentage_error: 757.3287\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 270.03052\n",
      "Epoch 272/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1374.0029 - mean_absolute_percentage_error: 1374.0029 - val_loss: 1444.0748 - val_mean_absolute_percentage_error: 1444.0748\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 270.03052\n",
      "Epoch 273/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1544.8343 - mean_absolute_percentage_error: 1544.8343 - val_loss: 390.2874 - val_mean_absolute_percentage_error: 390.2874\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 270.03052\n",
      "Epoch 274/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1533.2368 - mean_absolute_percentage_error: 1533.2368 - val_loss: 2261.1921 - val_mean_absolute_percentage_error: 2261.1921\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 270.03052\n",
      "Epoch 275/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1889.4089 - mean_absolute_percentage_error: 1889.4089 - val_loss: 2949.4658 - val_mean_absolute_percentage_error: 2949.4658\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 270.03052\n",
      "Epoch 276/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1825.5834 - mean_absolute_percentage_error: 1825.5834 - val_loss: 1894.6748 - val_mean_absolute_percentage_error: 1894.6748\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 270.03052\n",
      "Epoch 277/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1509.1900 - mean_absolute_percentage_error: 1509.1900 - val_loss: 754.0895 - val_mean_absolute_percentage_error: 754.0895\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 270.03052\n",
      "Epoch 278/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1373.5460 - mean_absolute_percentage_error: 1373.5460 - val_loss: 1441.6423 - val_mean_absolute_percentage_error: 1441.6423\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 270.03052\n",
      "Epoch 279/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1542.9055 - mean_absolute_percentage_error: 1542.9055 - val_loss: 388.5002 - val_mean_absolute_percentage_error: 388.5002\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 270.03052\n",
      "Epoch 280/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1532.4635 - mean_absolute_percentage_error: 1532.4635 - val_loss: 2260.2566 - val_mean_absolute_percentage_error: 2260.2566\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 270.03052\n",
      "Epoch 281/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1889.1494 - mean_absolute_percentage_error: 1889.1494 - val_loss: 2947.1194 - val_mean_absolute_percentage_error: 2947.1194\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 270.03052\n",
      "Epoch 282/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1825.2391 - mean_absolute_percentage_error: 1825.2391 - val_loss: 1893.7791 - val_mean_absolute_percentage_error: 1893.7791\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 270.03052\n",
      "Epoch 283/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1508.7028 - mean_absolute_percentage_error: 1508.7028 - val_loss: 752.2921 - val_mean_absolute_percentage_error: 752.2921\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 270.03052\n",
      "Epoch 284/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1372.8645 - mean_absolute_percentage_error: 1372.8645 - val_loss: 1440.6870 - val_mean_absolute_percentage_error: 1440.6870\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 270.03052\n",
      "Epoch 285/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1543.2471 - mean_absolute_percentage_error: 1543.2471 - val_loss: 387.9156 - val_mean_absolute_percentage_error: 387.9156\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 270.03052\n",
      "Epoch 286/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1532.2810 - mean_absolute_percentage_error: 1532.2810 - val_loss: 2258.0549 - val_mean_absolute_percentage_error: 2258.0549\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 270.03052\n",
      "Epoch 287/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1887.9065 - mean_absolute_percentage_error: 1887.9065 - val_loss: 2945.2949 - val_mean_absolute_percentage_error: 2945.2949\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 270.03052\n",
      "Epoch 288/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1824.2834 - mean_absolute_percentage_error: 1824.2834 - val_loss: 1889.9508 - val_mean_absolute_percentage_error: 1889.9508\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 270.03052\n",
      "Epoch 289/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1509.0072 - mean_absolute_percentage_error: 1509.0072 - val_loss: 753.4330 - val_mean_absolute_percentage_error: 753.4330\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 270.03052\n",
      "Epoch 290/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1372.7270 - mean_absolute_percentage_error: 1372.7270 - val_loss: 1441.2449 - val_mean_absolute_percentage_error: 1441.2449\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 270.03052\n",
      "Epoch 291/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1542.2012 - mean_absolute_percentage_error: 1542.2012 - val_loss: 388.0194 - val_mean_absolute_percentage_error: 388.0194\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 270.03052\n",
      "Epoch 292/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1533.1679 - mean_absolute_percentage_error: 1533.1679 - val_loss: 2258.9717 - val_mean_absolute_percentage_error: 2258.9717\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 270.03052\n",
      "Epoch 293/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1887.3210 - mean_absolute_percentage_error: 1887.3210 - val_loss: 2942.3613 - val_mean_absolute_percentage_error: 2942.3613\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 270.03052\n",
      "Epoch 294/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1823.3239 - mean_absolute_percentage_error: 1823.3239 - val_loss: 1889.6056 - val_mean_absolute_percentage_error: 1889.6056\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 270.03052\n",
      "Epoch 295/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1508.5282 - mean_absolute_percentage_error: 1508.5282 - val_loss: 758.7550 - val_mean_absolute_percentage_error: 758.7550\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 270.03052\n",
      "Epoch 296/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1373.8621 - mean_absolute_percentage_error: 1373.8621 - val_loss: 1443.5953 - val_mean_absolute_percentage_error: 1443.5953\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 270.03052\n",
      "Epoch 297/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1542.3819 - mean_absolute_percentage_error: 1542.3819 - val_loss: 388.4360 - val_mean_absolute_percentage_error: 388.4360\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 270.03052\n",
      "Epoch 298/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1532.2820 - mean_absolute_percentage_error: 1532.2820 - val_loss: 2259.9082 - val_mean_absolute_percentage_error: 2259.9082\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 270.03052\n",
      "Epoch 299/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1888.5358 - mean_absolute_percentage_error: 1888.5358 - val_loss: 2946.9502 - val_mean_absolute_percentage_error: 2946.9502\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 270.03052\n",
      "Epoch 300/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1825.0887 - mean_absolute_percentage_error: 1825.0887 - val_loss: 1896.4595 - val_mean_absolute_percentage_error: 1896.4595\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 270.03052\n",
      "Epoch 301/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1508.7090 - mean_absolute_percentage_error: 1508.7090 - val_loss: 750.1136 - val_mean_absolute_percentage_error: 750.1136\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 270.03052\n",
      "Epoch 302/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1370.9769 - mean_absolute_percentage_error: 1370.9769 - val_loss: 1436.9730 - val_mean_absolute_percentage_error: 1436.9730\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 270.03052\n",
      "Epoch 303/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.8973 - mean_absolute_percentage_error: 1540.8973 - val_loss: 384.8029 - val_mean_absolute_percentage_error: 384.8029\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 270.03052\n",
      "Epoch 304/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1531.1670 - mean_absolute_percentage_error: 1531.1670 - val_loss: 2261.1924 - val_mean_absolute_percentage_error: 2261.1924\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 270.03052\n",
      "Epoch 305/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1888.4964 - mean_absolute_percentage_error: 1888.4964 - val_loss: 2948.3528 - val_mean_absolute_percentage_error: 2948.3528\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 270.03052\n",
      "Epoch 306/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1825.6318 - mean_absolute_percentage_error: 1825.6318 - val_loss: 1893.1284 - val_mean_absolute_percentage_error: 1893.1284\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 270.03052\n",
      "Epoch 307/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1509.2568 - mean_absolute_percentage_error: 1509.2568 - val_loss: 752.3318 - val_mean_absolute_percentage_error: 752.3318\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 270.03052\n",
      "Epoch 308/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1371.6640 - mean_absolute_percentage_error: 1371.6640 - val_loss: 1440.3063 - val_mean_absolute_percentage_error: 1440.3063\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 270.03052\n",
      "Epoch 309/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1541.5402 - mean_absolute_percentage_error: 1541.5402 - val_loss: 385.7735 - val_mean_absolute_percentage_error: 385.7735\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 270.03052\n",
      "Epoch 310/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1531.0679 - mean_absolute_percentage_error: 1531.0679 - val_loss: 2260.6436 - val_mean_absolute_percentage_error: 2260.6436\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 270.03052\n",
      "Epoch 311/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1887.3315 - mean_absolute_percentage_error: 1887.3315 - val_loss: 2952.4854 - val_mean_absolute_percentage_error: 2952.4854\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 270.03052\n",
      "Epoch 312/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1825.9441 - mean_absolute_percentage_error: 1825.9441 - val_loss: 1899.8472 - val_mean_absolute_percentage_error: 1899.8472\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 270.03052\n",
      "Epoch 313/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1507.9528 - mean_absolute_percentage_error: 1507.9528 - val_loss: 749.9666 - val_mean_absolute_percentage_error: 749.9666\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 270.03052\n",
      "Epoch 314/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1370.4435 - mean_absolute_percentage_error: 1370.4435 - val_loss: 1437.5452 - val_mean_absolute_percentage_error: 1437.5452\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 270.03052\n",
      "Epoch 315/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.2266 - mean_absolute_percentage_error: 1540.2266 - val_loss: 382.4028 - val_mean_absolute_percentage_error: 382.4028\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 270.03052\n",
      "Epoch 316/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1530.8806 - mean_absolute_percentage_error: 1530.8806 - val_loss: 2265.6436 - val_mean_absolute_percentage_error: 2265.6436\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 270.03052\n",
      "Epoch 317/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1889.2434 - mean_absolute_percentage_error: 1889.2434 - val_loss: 2961.4702 - val_mean_absolute_percentage_error: 2961.4702\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 270.03052\n",
      "Epoch 318/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1827.7829 - mean_absolute_percentage_error: 1827.7829 - val_loss: 1897.2183 - val_mean_absolute_percentage_error: 1897.2183\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 270.03052\n",
      "Epoch 319/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1507.9889 - mean_absolute_percentage_error: 1507.9889 - val_loss: 751.7282 - val_mean_absolute_percentage_error: 751.7282\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 270.03052\n",
      "Epoch 320/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1370.7126 - mean_absolute_percentage_error: 1370.7126 - val_loss: 1436.5015 - val_mean_absolute_percentage_error: 1436.5015\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 270.03052\n",
      "Epoch 321/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1540.5755 - mean_absolute_percentage_error: 1540.5755 - val_loss: 383.6419 - val_mean_absolute_percentage_error: 383.6419\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 270.03052\n",
      "Epoch 322/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1530.1799 - mean_absolute_percentage_error: 1530.1799 - val_loss: 2265.4478 - val_mean_absolute_percentage_error: 2265.4478\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 270.03052\n",
      "Epoch 323/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1889.2895 - mean_absolute_percentage_error: 1889.2895 - val_loss: 2949.3369 - val_mean_absolute_percentage_error: 2949.3369\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 270.03052\n",
      "Epoch 324/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1824.1514 - mean_absolute_percentage_error: 1824.1514 - val_loss: 1894.6061 - val_mean_absolute_percentage_error: 1894.6061\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 270.03052\n",
      "Epoch 325/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1507.5151 - mean_absolute_percentage_error: 1507.5151 - val_loss: 749.1155 - val_mean_absolute_percentage_error: 749.1155\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 270.03052\n",
      "Epoch 326/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1370.1896 - mean_absolute_percentage_error: 1370.1896 - val_loss: 1436.2434 - val_mean_absolute_percentage_error: 1436.2434\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 270.03052\n",
      "Epoch 327/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.5742 - mean_absolute_percentage_error: 1540.5742 - val_loss: 386.0579 - val_mean_absolute_percentage_error: 386.0579\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 270.03052\n",
      "Epoch 328/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1530.5376 - mean_absolute_percentage_error: 1530.5376 - val_loss: 2258.7263 - val_mean_absolute_percentage_error: 2258.7263\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 270.03052\n",
      "Epoch 329/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1886.6645 - mean_absolute_percentage_error: 1886.6645 - val_loss: 2943.0359 - val_mean_absolute_percentage_error: 2943.0359\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 270.03052\n",
      "Epoch 330/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1823.7017 - mean_absolute_percentage_error: 1823.7017 - val_loss: 1893.6017 - val_mean_absolute_percentage_error: 1893.6017\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 270.03052\n",
      "Epoch 331/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1506.9764 - mean_absolute_percentage_error: 1506.9764 - val_loss: 749.3636 - val_mean_absolute_percentage_error: 749.3636\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 270.03052\n",
      "Epoch 332/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1370.3493 - mean_absolute_percentage_error: 1370.3493 - val_loss: 1434.8530 - val_mean_absolute_percentage_error: 1434.8530\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 270.03052\n",
      "Epoch 333/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.1227 - mean_absolute_percentage_error: 1540.1227 - val_loss: 381.5102 - val_mean_absolute_percentage_error: 381.5102\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 270.03052\n",
      "Epoch 334/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1530.4084 - mean_absolute_percentage_error: 1530.4084 - val_loss: 2261.4705 - val_mean_absolute_percentage_error: 2261.4705\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 270.03052\n",
      "Epoch 335/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1887.3731 - mean_absolute_percentage_error: 1887.3731 - val_loss: 2946.0986 - val_mean_absolute_percentage_error: 2946.0986\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 270.03052\n",
      "Epoch 336/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1823.7932 - mean_absolute_percentage_error: 1823.7932 - val_loss: 1893.6279 - val_mean_absolute_percentage_error: 1893.6279\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 270.03052\n",
      "Epoch 337/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1506.7854 - mean_absolute_percentage_error: 1506.7854 - val_loss: 748.9559 - val_mean_absolute_percentage_error: 748.9559\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 270.03052\n",
      "Epoch 338/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1369.6629 - mean_absolute_percentage_error: 1369.6629 - val_loss: 1435.5554 - val_mean_absolute_percentage_error: 1435.5554\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 270.03052\n",
      "Epoch 339/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.7111 - mean_absolute_percentage_error: 1540.7111 - val_loss: 379.5964 - val_mean_absolute_percentage_error: 379.5964\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 270.03052\n",
      "Epoch 340/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1529.9528 - mean_absolute_percentage_error: 1529.9528 - val_loss: 2261.9204 - val_mean_absolute_percentage_error: 2261.9204\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 270.03052\n",
      "Epoch 341/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1887.8972 - mean_absolute_percentage_error: 1887.8972 - val_loss: 2945.1565 - val_mean_absolute_percentage_error: 2945.1565\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 270.03052\n",
      "Epoch 342/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1822.9191 - mean_absolute_percentage_error: 1822.9191 - val_loss: 1893.1031 - val_mean_absolute_percentage_error: 1893.1031\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 270.03052\n",
      "Epoch 343/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1507.0344 - mean_absolute_percentage_error: 1507.0344 - val_loss: 747.9670 - val_mean_absolute_percentage_error: 747.9670\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 270.03052\n",
      "Epoch 344/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1369.8745 - mean_absolute_percentage_error: 1369.8745 - val_loss: 1433.3542 - val_mean_absolute_percentage_error: 1433.3542\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 270.03052\n",
      "Epoch 345/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1539.3608 - mean_absolute_percentage_error: 1539.3608 - val_loss: 383.0790 - val_mean_absolute_percentage_error: 383.0790\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 270.03052\n",
      "Epoch 346/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1529.9815 - mean_absolute_percentage_error: 1529.9815 - val_loss: 2262.8149 - val_mean_absolute_percentage_error: 2262.8149\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 270.03052\n",
      "Epoch 347/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1887.8942 - mean_absolute_percentage_error: 1887.8942 - val_loss: 2949.3921 - val_mean_absolute_percentage_error: 2949.3921\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 270.03052\n",
      "Epoch 348/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1823.9779 - mean_absolute_percentage_error: 1823.9779 - val_loss: 1895.6062 - val_mean_absolute_percentage_error: 1895.6062\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 270.03052\n",
      "Epoch 349/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1506.6253 - mean_absolute_percentage_error: 1506.6253 - val_loss: 747.2759 - val_mean_absolute_percentage_error: 747.2759\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 270.03052\n",
      "Epoch 350/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1369.5502 - mean_absolute_percentage_error: 1369.5502 - val_loss: 1434.9521 - val_mean_absolute_percentage_error: 1434.9521\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 270.03052\n",
      "Epoch 351/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1539.4797 - mean_absolute_percentage_error: 1539.4797 - val_loss: 382.8973 - val_mean_absolute_percentage_error: 382.8973\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 270.03052\n",
      "Epoch 352/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1530.0730 - mean_absolute_percentage_error: 1530.0730 - val_loss: 2259.1108 - val_mean_absolute_percentage_error: 2259.1108\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 270.03052\n",
      "Epoch 353/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1886.4093 - mean_absolute_percentage_error: 1886.4093 - val_loss: 2943.0771 - val_mean_absolute_percentage_error: 2943.0771\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 270.03052\n",
      "Epoch 354/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1822.7712 - mean_absolute_percentage_error: 1822.7712 - val_loss: 1891.6985 - val_mean_absolute_percentage_error: 1891.6985\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 270.03052\n",
      "Epoch 355/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1506.1827 - mean_absolute_percentage_error: 1506.1827 - val_loss: 750.2178 - val_mean_absolute_percentage_error: 750.2178\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 270.03052\n",
      "Epoch 356/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1369.2203 - mean_absolute_percentage_error: 1369.2203 - val_loss: 1442.0426 - val_mean_absolute_percentage_error: 1442.0426\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 270.03052\n",
      "Epoch 357/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.8535 - mean_absolute_percentage_error: 1540.8535 - val_loss: 388.6195 - val_mean_absolute_percentage_error: 388.6195\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 270.03052\n",
      "Epoch 358/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1529.4965 - mean_absolute_percentage_error: 1529.4965 - val_loss: 2255.2002 - val_mean_absolute_percentage_error: 2255.2002\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 270.03052\n",
      "Epoch 359/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1886.3567 - mean_absolute_percentage_error: 1886.3567 - val_loss: 2944.1270 - val_mean_absolute_percentage_error: 2944.1270\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 270.03052\n",
      "Epoch 360/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1822.1734 - mean_absolute_percentage_error: 1822.1734 - val_loss: 1890.4269 - val_mean_absolute_percentage_error: 1890.4269\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 270.03052\n",
      "Epoch 361/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1505.6319 - mean_absolute_percentage_error: 1505.6319 - val_loss: 756.9000 - val_mean_absolute_percentage_error: 756.9000\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 270.03052\n",
      "Epoch 362/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1371.2303 - mean_absolute_percentage_error: 1371.2303 - val_loss: 1437.5181 - val_mean_absolute_percentage_error: 1437.5181\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 270.03052\n",
      "Epoch 363/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.1148 - mean_absolute_percentage_error: 1540.1148 - val_loss: 382.9466 - val_mean_absolute_percentage_error: 382.9466\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 270.03052\n",
      "Epoch 364/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1528.8883 - mean_absolute_percentage_error: 1528.8883 - val_loss: 2265.3718 - val_mean_absolute_percentage_error: 2265.3718\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 270.03052\n",
      "Epoch 365/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1889.5942 - mean_absolute_percentage_error: 1889.5942 - val_loss: 2947.4072 - val_mean_absolute_percentage_error: 2947.4072\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 270.03052\n",
      "Epoch 366/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1822.3279 - mean_absolute_percentage_error: 1822.3279 - val_loss: 1893.2206 - val_mean_absolute_percentage_error: 1893.2206\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 270.03052\n",
      "Epoch 367/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1506.1180 - mean_absolute_percentage_error: 1506.1180 - val_loss: 754.5708 - val_mean_absolute_percentage_error: 754.5708\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 270.03052\n",
      "Epoch 368/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1370.0675 - mean_absolute_percentage_error: 1370.0675 - val_loss: 1440.9258 - val_mean_absolute_percentage_error: 1440.9258\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 270.03052\n",
      "Epoch 369/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1540.8716 - mean_absolute_percentage_error: 1540.8716 - val_loss: 386.7885 - val_mean_absolute_percentage_error: 386.7885\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 270.03052\n",
      "Epoch 370/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1528.9880 - mean_absolute_percentage_error: 1528.9880 - val_loss: 2257.9851 - val_mean_absolute_percentage_error: 2257.9851\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 270.03052\n",
      "Epoch 371/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1885.5039 - mean_absolute_percentage_error: 1885.5039 - val_loss: 2943.0891 - val_mean_absolute_percentage_error: 2943.0891\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 270.03052\n",
      "Epoch 372/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1822.5647 - mean_absolute_percentage_error: 1822.5647 - val_loss: 1889.6361 - val_mean_absolute_percentage_error: 1889.6361\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 270.03052\n",
      "Epoch 373/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1506.1474 - mean_absolute_percentage_error: 1506.1474 - val_loss: 749.5048 - val_mean_absolute_percentage_error: 749.5048\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 270.03052\n",
      "Epoch 374/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1368.3159 - mean_absolute_percentage_error: 1368.3159 - val_loss: 1435.0726 - val_mean_absolute_percentage_error: 1435.0726\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 270.03052\n",
      "Epoch 375/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1538.8528 - mean_absolute_percentage_error: 1538.8528 - val_loss: 382.4640 - val_mean_absolute_percentage_error: 382.4640\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 270.03052\n",
      "Epoch 376/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1529.2264 - mean_absolute_percentage_error: 1529.2264 - val_loss: 2254.8628 - val_mean_absolute_percentage_error: 2254.8628\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 270.03052\n",
      "Epoch 377/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1884.8110 - mean_absolute_percentage_error: 1884.8110 - val_loss: 2940.0740 - val_mean_absolute_percentage_error: 2940.0740\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 270.03052\n",
      "Epoch 378/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1820.9263 - mean_absolute_percentage_error: 1820.9263 - val_loss: 1887.6473 - val_mean_absolute_percentage_error: 1887.6473\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 270.03052\n",
      "Epoch 379/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1507.4814 - mean_absolute_percentage_error: 1507.4814 - val_loss: 750.5125 - val_mean_absolute_percentage_error: 750.5125\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 270.03052\n",
      "Epoch 380/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1368.6442 - mean_absolute_percentage_error: 1368.6442 - val_loss: 1432.8375 - val_mean_absolute_percentage_error: 1432.8375\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 270.03052\n",
      "Epoch 381/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1539.8199 - mean_absolute_percentage_error: 1539.8199 - val_loss: 384.8944 - val_mean_absolute_percentage_error: 384.8944\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 270.03052\n",
      "Epoch 382/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1529.1505 - mean_absolute_percentage_error: 1529.1505 - val_loss: 2257.4998 - val_mean_absolute_percentage_error: 2257.4998\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 270.03052\n",
      "Epoch 383/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1886.0601 - mean_absolute_percentage_error: 1886.0601 - val_loss: 2944.6975 - val_mean_absolute_percentage_error: 2944.6975\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 270.03052\n",
      "Epoch 384/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1822.1456 - mean_absolute_percentage_error: 1822.1456 - val_loss: 1891.7891 - val_mean_absolute_percentage_error: 1891.7891\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 270.03052\n",
      "Epoch 385/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1506.4063 - mean_absolute_percentage_error: 1506.4063 - val_loss: 749.1588 - val_mean_absolute_percentage_error: 749.1588\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 270.03052\n",
      "Epoch 386/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1368.1885 - mean_absolute_percentage_error: 1368.1885 - val_loss: 1438.8107 - val_mean_absolute_percentage_error: 1438.8107\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 270.03052\n",
      "Epoch 387/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.1935 - mean_absolute_percentage_error: 1540.1935 - val_loss: 390.1189 - val_mean_absolute_percentage_error: 390.1189\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 270.03052\n",
      "Epoch 388/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1529.3292 - mean_absolute_percentage_error: 1529.3292 - val_loss: 2254.9905 - val_mean_absolute_percentage_error: 2254.9905\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 270.03052\n",
      "Epoch 389/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1885.4115 - mean_absolute_percentage_error: 1885.4115 - val_loss: 2945.8550 - val_mean_absolute_percentage_error: 2945.8550\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 270.03052\n",
      "Epoch 390/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1824.1109 - mean_absolute_percentage_error: 1824.1109 - val_loss: 1893.4287 - val_mean_absolute_percentage_error: 1893.4287\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 270.03052\n",
      "Epoch 391/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1505.5960 - mean_absolute_percentage_error: 1505.5960 - val_loss: 751.0861 - val_mean_absolute_percentage_error: 751.0861\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 270.03052\n",
      "Epoch 392/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1369.9379 - mean_absolute_percentage_error: 1369.9379 - val_loss: 1433.6968 - val_mean_absolute_percentage_error: 1433.6968\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 270.03052\n",
      "Epoch 393/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1538.6008 - mean_absolute_percentage_error: 1538.6008 - val_loss: 377.7023 - val_mean_absolute_percentage_error: 377.7023\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 270.03052\n",
      "Epoch 394/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1528.5380 - mean_absolute_percentage_error: 1528.5380 - val_loss: 2259.6021 - val_mean_absolute_percentage_error: 2259.6021\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 270.03052\n",
      "Epoch 395/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1886.9568 - mean_absolute_percentage_error: 1886.9568 - val_loss: 2941.1040 - val_mean_absolute_percentage_error: 2941.1040\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 270.03052\n",
      "Epoch 396/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1821.8404 - mean_absolute_percentage_error: 1821.8404 - val_loss: 1884.0095 - val_mean_absolute_percentage_error: 1884.0095\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 270.03052\n",
      "Epoch 397/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1506.3560 - mean_absolute_percentage_error: 1506.3560 - val_loss: 760.0544 - val_mean_absolute_percentage_error: 760.0544\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 270.03052\n",
      "Epoch 398/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1373.4538 - mean_absolute_percentage_error: 1373.4538 - val_loss: 1440.6401 - val_mean_absolute_percentage_error: 1440.6401\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 270.03052\n",
      "Epoch 399/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1540.3301 - mean_absolute_percentage_error: 1540.3301 - val_loss: 385.5884 - val_mean_absolute_percentage_error: 385.5884\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 270.03052\n",
      "Epoch 400/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1528.9767 - mean_absolute_percentage_error: 1528.9767 - val_loss: 2252.7566 - val_mean_absolute_percentage_error: 2252.7566\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 270.03052\n",
      "Epoch 401/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1884.0872 - mean_absolute_percentage_error: 1884.0872 - val_loss: 2943.6250 - val_mean_absolute_percentage_error: 2943.6250\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 270.03052\n",
      "Epoch 402/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1821.3058 - mean_absolute_percentage_error: 1821.3058 - val_loss: 1891.0707 - val_mean_absolute_percentage_error: 1891.0707\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 270.03052\n",
      "Epoch 403/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1506.3179 - mean_absolute_percentage_error: 1506.3179 - val_loss: 756.0602 - val_mean_absolute_percentage_error: 756.0602\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 270.03052\n",
      "Epoch 404/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1371.7151 - mean_absolute_percentage_error: 1371.7151 - val_loss: 1437.0426 - val_mean_absolute_percentage_error: 1437.0426\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 270.03052\n",
      "Epoch 405/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1538.7132 - mean_absolute_percentage_error: 1538.7132 - val_loss: 387.1601 - val_mean_absolute_percentage_error: 387.1601\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 270.03052\n",
      "Epoch 406/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1529.2402 - mean_absolute_percentage_error: 1529.2402 - val_loss: 2257.0613 - val_mean_absolute_percentage_error: 2257.0613\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 270.03052\n",
      "Epoch 407/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1885.6929 - mean_absolute_percentage_error: 1885.6929 - val_loss: 2939.5298 - val_mean_absolute_percentage_error: 2939.5298\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 270.03052\n",
      "Epoch 408/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1821.4157 - mean_absolute_percentage_error: 1821.4157 - val_loss: 1883.8081 - val_mean_absolute_percentage_error: 1883.8081\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 270.03052\n",
      "Epoch 409/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1505.7538 - mean_absolute_percentage_error: 1505.7538 - val_loss: 751.5798 - val_mean_absolute_percentage_error: 751.5798\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 270.03052\n",
      "Epoch 410/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1369.8569 - mean_absolute_percentage_error: 1369.8569 - val_loss: 1436.5983 - val_mean_absolute_percentage_error: 1436.5983\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 270.03052\n",
      "Epoch 411/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1539.6351 - mean_absolute_percentage_error: 1539.6351 - val_loss: 380.7302 - val_mean_absolute_percentage_error: 380.7302\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 270.03052\n",
      "Epoch 412/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1529.5606 - mean_absolute_percentage_error: 1529.5606 - val_loss: 2252.2903 - val_mean_absolute_percentage_error: 2252.2903\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 270.03052\n",
      "Epoch 413/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1884.1719 - mean_absolute_percentage_error: 1884.1719 - val_loss: 2946.1294 - val_mean_absolute_percentage_error: 2946.1294\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 270.03052\n",
      "Epoch 414/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1823.0791 - mean_absolute_percentage_error: 1823.0791 - val_loss: 1892.0441 - val_mean_absolute_percentage_error: 1892.0441\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 270.03052\n",
      "Epoch 415/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1505.0090 - mean_absolute_percentage_error: 1505.0090 - val_loss: 748.7079 - val_mean_absolute_percentage_error: 748.7079\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 270.03052\n",
      "Epoch 416/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1370.3924 - mean_absolute_percentage_error: 1370.3924 - val_loss: 1432.5972 - val_mean_absolute_percentage_error: 1432.5972\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 270.03052\n",
      "Epoch 417/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1537.5684 - mean_absolute_percentage_error: 1537.5684 - val_loss: 386.0347 - val_mean_absolute_percentage_error: 386.0347\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 270.03052\n",
      "Epoch 418/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1528.4326 - mean_absolute_percentage_error: 1528.4326 - val_loss: 2252.6797 - val_mean_absolute_percentage_error: 2252.6797\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 270.03052\n",
      "Epoch 419/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1883.9861 - mean_absolute_percentage_error: 1883.9861 - val_loss: 2944.4524 - val_mean_absolute_percentage_error: 2944.4524\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 270.03052\n",
      "Epoch 420/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1821.8182 - mean_absolute_percentage_error: 1821.8182 - val_loss: 1884.3337 - val_mean_absolute_percentage_error: 1884.3337\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 270.03052\n",
      "Epoch 421/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1506.0298 - mean_absolute_percentage_error: 1506.0298 - val_loss: 748.3599 - val_mean_absolute_percentage_error: 748.3599\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 270.03052\n",
      "Epoch 422/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1368.4872 - mean_absolute_percentage_error: 1368.4872 - val_loss: 1440.8656 - val_mean_absolute_percentage_error: 1440.8656\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 270.03052\n",
      "Epoch 423/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1540.1355 - mean_absolute_percentage_error: 1540.1355 - val_loss: 384.3569 - val_mean_absolute_percentage_error: 384.3569\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 270.03052\n",
      "Epoch 424/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1527.5249 - mean_absolute_percentage_error: 1527.5249 - val_loss: 2264.3613 - val_mean_absolute_percentage_error: 2264.3613\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 270.03052\n",
      "Epoch 425/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1888.2603 - mean_absolute_percentage_error: 1888.2603 - val_loss: 2945.5654 - val_mean_absolute_percentage_error: 2945.5654\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 270.03052\n",
      "Epoch 426/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1821.1380 - mean_absolute_percentage_error: 1821.1380 - val_loss: 1884.5184 - val_mean_absolute_percentage_error: 1884.5184\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 270.03052\n",
      "Epoch 427/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1506.5528 - mean_absolute_percentage_error: 1506.5528 - val_loss: 754.4411 - val_mean_absolute_percentage_error: 754.4411\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 270.03052\n",
      "Epoch 428/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1370.4731 - mean_absolute_percentage_error: 1370.4731 - val_loss: 1430.3824 - val_mean_absolute_percentage_error: 1430.3824\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 270.03052\n",
      "Epoch 429/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1538.3630 - mean_absolute_percentage_error: 1538.3630 - val_loss: 381.4261 - val_mean_absolute_percentage_error: 381.4261\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 270.03052\n",
      "Epoch 430/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1528.7636 - mean_absolute_percentage_error: 1528.7636 - val_loss: 2260.3201 - val_mean_absolute_percentage_error: 2260.3201\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 270.03052\n",
      "Epoch 431/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1886.1273 - mean_absolute_percentage_error: 1886.1273 - val_loss: 2946.5168 - val_mean_absolute_percentage_error: 2946.5168\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 270.03052\n",
      "Epoch 432/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1822.5204 - mean_absolute_percentage_error: 1822.5204 - val_loss: 1892.0430 - val_mean_absolute_percentage_error: 1892.0430\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 270.03052\n",
      "Epoch 433/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1504.6663 - mean_absolute_percentage_error: 1504.6663 - val_loss: 752.3389 - val_mean_absolute_percentage_error: 752.3389\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 270.03052\n",
      "Epoch 434/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1369.7355 - mean_absolute_percentage_error: 1369.7355 - val_loss: 1457.2590 - val_mean_absolute_percentage_error: 1457.2590\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 270.03052\n",
      "Epoch 435/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1543.7223 - mean_absolute_percentage_error: 1543.7223 - val_loss: 385.9098 - val_mean_absolute_percentage_error: 385.9098\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 270.03052\n",
      "Epoch 436/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1528.1154 - mean_absolute_percentage_error: 1528.1154 - val_loss: 2255.4690 - val_mean_absolute_percentage_error: 2255.4690\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 270.03052\n",
      "Epoch 437/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1883.6202 - mean_absolute_percentage_error: 1883.6202 - val_loss: 2961.9485 - val_mean_absolute_percentage_error: 2961.9485\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 270.03052\n",
      "Epoch 438/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1827.0023 - mean_absolute_percentage_error: 1827.0023 - val_loss: 1896.9237 - val_mean_absolute_percentage_error: 1896.9237\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 270.03052\n",
      "Epoch 439/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1505.9351 - mean_absolute_percentage_error: 1505.9351 - val_loss: 749.3444 - val_mean_absolute_percentage_error: 749.3444\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 270.03052\n",
      "Epoch 440/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1368.2838 - mean_absolute_percentage_error: 1368.2838 - val_loss: 1427.4047 - val_mean_absolute_percentage_error: 1427.4047\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 270.03052\n",
      "Epoch 441/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1538.2901 - mean_absolute_percentage_error: 1538.2901 - val_loss: 371.0594 - val_mean_absolute_percentage_error: 371.0594\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 270.03052\n",
      "Epoch 442/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1529.3952 - mean_absolute_percentage_error: 1529.3952 - val_loss: 2261.6001 - val_mean_absolute_percentage_error: 2261.6001\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 270.03052\n",
      "Epoch 443/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1887.2695 - mean_absolute_percentage_error: 1887.2695 - val_loss: 2940.2456 - val_mean_absolute_percentage_error: 2940.2456\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 270.03052\n",
      "Epoch 444/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1820.4279 - mean_absolute_percentage_error: 1820.4279 - val_loss: 1884.8394 - val_mean_absolute_percentage_error: 1884.8394\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 270.03052\n",
      "Epoch 445/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1505.4377 - mean_absolute_percentage_error: 1505.4377 - val_loss: 748.4375 - val_mean_absolute_percentage_error: 748.4375\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 270.03052\n",
      "Epoch 446/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1368.1508 - mean_absolute_percentage_error: 1368.1508 - val_loss: 1430.9683 - val_mean_absolute_percentage_error: 1430.9683\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 270.03052\n",
      "Epoch 447/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1538.7546 - mean_absolute_percentage_error: 1538.7546 - val_loss: 375.6158 - val_mean_absolute_percentage_error: 375.6158\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 270.03052\n",
      "Epoch 448/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1529.0601 - mean_absolute_percentage_error: 1529.0601 - val_loss: 2250.4065 - val_mean_absolute_percentage_error: 2250.4065\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 270.03052\n",
      "Epoch 449/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1883.2732 - mean_absolute_percentage_error: 1883.2732 - val_loss: 2937.1235 - val_mean_absolute_percentage_error: 2937.1235\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 270.03052\n",
      "Epoch 450/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1820.1904 - mean_absolute_percentage_error: 1820.1904 - val_loss: 1889.4407 - val_mean_absolute_percentage_error: 1889.4407\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 270.03052\n",
      "Epoch 451/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1505.6019 - mean_absolute_percentage_error: 1505.6019 - val_loss: 751.0316 - val_mean_absolute_percentage_error: 751.0316\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 270.03052\n",
      "Epoch 452/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1369.0164 - mean_absolute_percentage_error: 1369.0164 - val_loss: 1437.7684 - val_mean_absolute_percentage_error: 1437.7684\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 270.03052\n",
      "Epoch 453/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1539.1880 - mean_absolute_percentage_error: 1539.1880 - val_loss: 378.1655 - val_mean_absolute_percentage_error: 378.1655\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 270.03052\n",
      "Epoch 454/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1527.9078 - mean_absolute_percentage_error: 1527.9078 - val_loss: 2263.4868 - val_mean_absolute_percentage_error: 2263.4868\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 270.03052\n",
      "Epoch 455/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1887.8842 - mean_absolute_percentage_error: 1887.8842 - val_loss: 2936.6846 - val_mean_absolute_percentage_error: 2936.6846\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 270.03052\n",
      "Epoch 456/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1819.3053 - mean_absolute_percentage_error: 1819.3053 - val_loss: 1873.3882 - val_mean_absolute_percentage_error: 1873.3882\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 270.03052\n",
      "Epoch 457/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1507.4159 - mean_absolute_percentage_error: 1507.4159 - val_loss: 755.8741 - val_mean_absolute_percentage_error: 755.8741\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 270.03052\n",
      "Epoch 458/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1370.0759 - mean_absolute_percentage_error: 1370.0759 - val_loss: 1433.9070 - val_mean_absolute_percentage_error: 1433.9070\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 270.03052\n",
      "Epoch 459/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1538.6375 - mean_absolute_percentage_error: 1538.6375 - val_loss: 387.9906 - val_mean_absolute_percentage_error: 387.9906\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 270.03052\n",
      "Epoch 460/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1528.0853 - mean_absolute_percentage_error: 1528.0853 - val_loss: 2390.8792 - val_mean_absolute_percentage_error: 2390.8792\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 270.03052\n",
      "Epoch 461/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1926.4241 - mean_absolute_percentage_error: 1926.4241 - val_loss: 2924.3000 - val_mean_absolute_percentage_error: 2924.3000\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 270.03052\n",
      "Epoch 462/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1819.3661 - mean_absolute_percentage_error: 1819.3661 - val_loss: 1886.7876 - val_mean_absolute_percentage_error: 1886.7876\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 270.03052\n",
      "Epoch 463/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1505.3310 - mean_absolute_percentage_error: 1505.3310 - val_loss: 746.9880 - val_mean_absolute_percentage_error: 746.9880\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 270.03052\n",
      "Epoch 464/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1367.1062 - mean_absolute_percentage_error: 1367.1062 - val_loss: 1427.2272 - val_mean_absolute_percentage_error: 1427.2272\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 270.03052\n",
      "Epoch 465/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1537.7842 - mean_absolute_percentage_error: 1537.7842 - val_loss: 379.8899 - val_mean_absolute_percentage_error: 379.8899\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 270.03052\n",
      "Epoch 466/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1528.8371 - mean_absolute_percentage_error: 1528.8371 - val_loss: 2253.7224 - val_mean_absolute_percentage_error: 2253.7224\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 270.03052\n",
      "Epoch 467/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1883.1308 - mean_absolute_percentage_error: 1883.1308 - val_loss: 2935.4800 - val_mean_absolute_percentage_error: 2935.4800\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 270.03052\n",
      "Epoch 468/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1819.6605 - mean_absolute_percentage_error: 1819.6605 - val_loss: 1892.6310 - val_mean_absolute_percentage_error: 1892.6310\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 270.03052\n",
      "Epoch 469/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1505.2750 - mean_absolute_percentage_error: 1505.2750 - val_loss: 740.6187 - val_mean_absolute_percentage_error: 740.6187\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 270.03052\n",
      "Epoch 470/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1364.8172 - mean_absolute_percentage_error: 1364.8172 - val_loss: 1433.9027 - val_mean_absolute_percentage_error: 1433.9027\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 270.03052\n",
      "Epoch 471/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1537.9522 - mean_absolute_percentage_error: 1537.9522 - val_loss: 377.8607 - val_mean_absolute_percentage_error: 377.8607\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 270.03052\n",
      "Epoch 472/500\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1529.0693 - mean_absolute_percentage_error: 1529.0693 - val_loss: 2262.4824 - val_mean_absolute_percentage_error: 2262.4824\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 270.03052\n",
      "Epoch 473/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1886.5847 - mean_absolute_percentage_error: 1886.5847 - val_loss: 2941.6829 - val_mean_absolute_percentage_error: 2941.6829\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 270.03052\n",
      "Epoch 474/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1822.2181 - mean_absolute_percentage_error: 1822.2181 - val_loss: 1891.7115 - val_mean_absolute_percentage_error: 1891.7115\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 270.03052\n",
      "Epoch 475/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1505.4071 - mean_absolute_percentage_error: 1505.4071 - val_loss: 747.6975 - val_mean_absolute_percentage_error: 747.6975\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 270.03052\n",
      "Epoch 476/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1368.8336 - mean_absolute_percentage_error: 1368.8336 - val_loss: 1430.1094 - val_mean_absolute_percentage_error: 1430.1094\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 270.03052\n",
      "Epoch 477/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1536.9963 - mean_absolute_percentage_error: 1536.9963 - val_loss: 379.8593 - val_mean_absolute_percentage_error: 379.8593\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 270.03052\n",
      "Epoch 478/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1527.6680 - mean_absolute_percentage_error: 1527.6680 - val_loss: 2257.8975 - val_mean_absolute_percentage_error: 2257.8975\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 270.03052\n",
      "Epoch 479/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1884.7536 - mean_absolute_percentage_error: 1884.7536 - val_loss: 2940.4138 - val_mean_absolute_percentage_error: 2940.4138\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 270.03052\n",
      "Epoch 480/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1820.7991 - mean_absolute_percentage_error: 1820.7991 - val_loss: 1892.1998 - val_mean_absolute_percentage_error: 1892.1998\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 270.03052\n",
      "Epoch 481/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1504.3316 - mean_absolute_percentage_error: 1504.3316 - val_loss: 751.6957 - val_mean_absolute_percentage_error: 751.6957\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 270.03052\n",
      "Epoch 482/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1368.9324 - mean_absolute_percentage_error: 1368.9324 - val_loss: 1432.0157 - val_mean_absolute_percentage_error: 1432.0157\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 270.03052\n",
      "Epoch 483/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1537.7680 - mean_absolute_percentage_error: 1537.7680 - val_loss: 370.2900 - val_mean_absolute_percentage_error: 370.2900\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 270.03052\n",
      "Epoch 484/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1528.9255 - mean_absolute_percentage_error: 1528.9255 - val_loss: 2254.0198 - val_mean_absolute_percentage_error: 2254.0198\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 270.03052\n",
      "Epoch 485/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1884.2174 - mean_absolute_percentage_error: 1884.2174 - val_loss: 2933.6531 - val_mean_absolute_percentage_error: 2933.6531\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 270.03052\n",
      "Epoch 486/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1818.7820 - mean_absolute_percentage_error: 1818.7820 - val_loss: 1884.9087 - val_mean_absolute_percentage_error: 1884.9087\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 270.03052\n",
      "Epoch 487/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1504.1572 - mean_absolute_percentage_error: 1504.1572 - val_loss: 746.4243 - val_mean_absolute_percentage_error: 746.4243\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 270.03052\n",
      "Epoch 488/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1367.2153 - mean_absolute_percentage_error: 1367.2153 - val_loss: 1437.9950 - val_mean_absolute_percentage_error: 1437.9950\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 270.03052\n",
      "Epoch 489/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1538.2854 - mean_absolute_percentage_error: 1538.2854 - val_loss: 385.5137 - val_mean_absolute_percentage_error: 385.5137\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 270.03052\n",
      "Epoch 490/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1528.3492 - mean_absolute_percentage_error: 1528.3492 - val_loss: 2252.3977 - val_mean_absolute_percentage_error: 2252.3977\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 270.03052\n",
      "Epoch 491/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1882.6224 - mean_absolute_percentage_error: 1882.6224 - val_loss: 2938.5745 - val_mean_absolute_percentage_error: 2938.5745\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 270.03052\n",
      "Epoch 492/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1820.6800 - mean_absolute_percentage_error: 1820.6800 - val_loss: 1896.8347 - val_mean_absolute_percentage_error: 1896.8347\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 270.03052\n",
      "Epoch 493/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1505.2674 - mean_absolute_percentage_error: 1505.2674 - val_loss: 757.0635 - val_mean_absolute_percentage_error: 757.0635\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 270.03052\n",
      "Epoch 494/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1371.7278 - mean_absolute_percentage_error: 1371.7278 - val_loss: 1429.6667 - val_mean_absolute_percentage_error: 1429.6667\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 270.03052\n",
      "Epoch 495/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1537.9751 - mean_absolute_percentage_error: 1537.9751 - val_loss: 379.7800 - val_mean_absolute_percentage_error: 379.7800\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 270.03052\n",
      "Epoch 496/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1528.2461 - mean_absolute_percentage_error: 1528.2461 - val_loss: 2247.3721 - val_mean_absolute_percentage_error: 2247.3721\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 270.03052\n",
      "Epoch 497/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1881.8759 - mean_absolute_percentage_error: 1881.8759 - val_loss: 2938.5566 - val_mean_absolute_percentage_error: 2938.5566\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 270.03052\n",
      "Epoch 498/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1819.1854 - mean_absolute_percentage_error: 1819.1854 - val_loss: 1889.6587 - val_mean_absolute_percentage_error: 1889.6587\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 270.03052\n",
      "Epoch 499/500\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1504.3899 - mean_absolute_percentage_error: 1504.3899 - val_loss: 760.7805 - val_mean_absolute_percentage_error: 760.7805\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 270.03052\n",
      "Epoch 500/500\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 1373.5553 - mean_absolute_percentage_error: 1373.5553 - val_loss: 1430.5142 - val_mean_absolute_percentage_error: 1430.5142\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 270.03052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2600299a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=32, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J_T9n5_xQ_01",
   "metadata": {
    "id": "J_T9n5_xQ_01"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ANN_on_IEEE_Bus_system.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
